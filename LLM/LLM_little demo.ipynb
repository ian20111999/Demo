{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenhongyan/opt/anaconda3/envs/pytorch/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Greedy methods without beam search do not support `num_return_sequences` different than 1 (got 5).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mencode(input_text, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# 设置生成参数（移除 attention_mask 参数）\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_return_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 批量生成 5 个序列\u001b[39;49;00m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.95\u001b[39;49m\n\u001b[1;32m     26\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# 解码并打印所有生成的文本\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, generated_sequence \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(output):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.10/site-packages/transformers/generation/utils.py:1688\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_model_class()\n\u001b[1;32m   1687\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# Pull this out first, we only use it for stopping criteria\u001b[39;00m\n\u001b[0;32m-> 1688\u001b[0m generation_config, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_generation_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1689\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_model_kwargs(model_kwargs\u001b[38;5;241m.\u001b[39mcopy())\n\u001b[1;32m   1690\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_assistant(assistant_model)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.10/site-packages/transformers/generation/utils.py:1391\u001b[0m, in \u001b[0;36mGenerationMixin._prepare_generation_config\u001b[0;34m(self, generation_config, **kwargs)\u001b[0m\n\u001b[1;32m   1389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[1;32m   1390\u001b[0m     generation_config \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(generation_config)\n\u001b[0;32m-> 1391\u001b[0m     model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1392\u001b[0m     \u001b[38;5;66;03m# If `generation_config` is provided, let's fallback ALL special tokens to the default values for the model\u001b[39;00m\n\u001b[1;32m   1393\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_model_generation_config:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:1207\u001b[0m, in \u001b[0;36mGenerationConfig.update\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1204\u001b[0m         to_remove\u001b[38;5;241m.\u001b[39mappend(key)\n\u001b[1;32m   1206\u001b[0m \u001b[38;5;66;03m# Confirm that the updated instance is still valid\u001b[39;00m\n\u001b[0;32m-> 1207\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1209\u001b[0m \u001b[38;5;66;03m# Remove all the attributes that were updated, without modifying the input dict\u001b[39;00m\n\u001b[1;32m   1210\u001b[0m unused_kwargs \u001b[38;5;241m=\u001b[39m {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m to_remove}\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:683\u001b[0m, in \u001b[0;36mGenerationConfig.validate\u001b[0;34m(self, is_init)\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_beams \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_sample \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m--> 683\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    684\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGreedy methods without beam search do not support `num_return_sequences` different than 1 \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    685\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_return_sequences\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    686\u001b[0m         )\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_return_sequences \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_beams:\n\u001b[1;32m    688\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    689\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`num_return_sequences` (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_return_sequences\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) has to be smaller or equal to `num_beams` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    690\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_beams\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    691\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Greedy methods without beam search do not support `num_return_sequences` different than 1 (got 5)."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# 加载模型和分词器\n",
    "model_name = \"gpt2\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# 将模型移动到GPU（如果可用）\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# 输入文本\n",
    "input_text = \"Once upon a time\"\n",
    "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# 设置生成参数（移除 attention_mask 参数）\n",
    "output = model.generate(\n",
    "    input_ids,\n",
    "    max_length=50,\n",
    "    num_return_sequences=1,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    temperature=0.7,\n",
    "    top_k=50,\n",
    "    top_p=0.95\n",
    ")\n",
    "\n",
    "# 解码并打印生成的文本\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text 1: Once upon a time in a dystopian future, there was a man who had no idea what he was talking about.\n",
      "\n",
      "Generated Text 2: Once upon a time in a dystopian future, there was a man who had the power to change the course of history.\n",
      "\n",
      "Generated Text 3: Once upon a time in a dystopian future, there was a man who had no idea what he was doing.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "# 加载模型和分词器\n",
    "model_name = \"gpt2\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# 将模型移动到GPU（如果可用）\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# 手动设置 pad_token_id，如果模型没有定义它\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# 输入文本\n",
    "input_text = \"Once upon a time in a dystopian future\"\n",
    "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# 使用混合精度加速生成（如果使用GPU）\n",
    "with autocast():\n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        max_length=100,  # 增加最大长度以生成更长的文本\n",
    "        num_return_sequences=3,  # 一次生成 3 个序列进行比较\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        temperature=0.8,  # 调整随机性\n",
    "        top_k=50,  # 限制候选词数量\n",
    "        top_p=0.9,  # 使用Nucleus采样\n",
    "        repetition_penalty=1.2,  # 惩罚重复\n",
    "        num_beams=5,  # 使用 Beam Search 增强生成质量\n",
    "        early_stopping=True,  # 当满足停止条件时提前停止\n",
    "        eos_token_id=tokenizer.convert_tokens_to_ids(\".\")  # 生成句号时停止\n",
    "    )\n",
    "\n",
    "# 解码并打印所有生成的文本\n",
    "for i, generated_sequence in enumerate(output):\n",
    "    generated_text = tokenizer.decode(generated_sequence, skip_special_tokens=True)\n",
    "    print(f\"Generated Text {i + 1}: {generated_text}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 1, Sequence 1: In the near future, humans and machines coexist in harmony, but that doesn't mean we won't have to work hard to make sure that doesn't happen.\n",
      "\n",
      "This article was originally published on The Conversation. Read the original article. Follow all of the Expert Voices issues and debates — and become part of the discussion — on Facebook, Twitter and Google +. The views expressed are those of the author and do not necessarily reflect the views of the publisher. This version of the article was originally published on Live Science.\n",
      "\n",
      "Prompt 1, Sequence 2: In the near future, humans and machines coexist in harmony, but that doesn't mean we won't have to work hard to make sure that doesn't happen.\n",
      "\n",
      "This article was originally published on The Conversation. Read the original article. Follow all of the Expert Voices issues and debates — and become part of the discussion — on Facebook, Twitter and Google +. The views expressed are those of the author and do not necessarily reflect the views of the publisher. This version of the article was originally published on LiveScience.\n",
      "\n",
      "Prompt 1, Sequence 3: In the near future, humans and machines coexist in harmony, but that doesn't mean we won't have to work hard to make sure that doesn't happen.\n",
      "\n",
      "This article was originally published on The Conversation. Read the original article. Follow all of the Expert Voices issues and debates — and become part of the discussion — on Facebook, Twitter and Google +. The views expressed are those of the author and do not necessarily reflect the views of the publisher. This version of the article was originally published on LiveScience.com.\n",
      "\n",
      "Prompt 1, Sequence 4: In the near future, humans and machines coexist in harmony, but that doesn't mean we won't have to work hard to make sure that doesn't happen.\n",
      "\n",
      "This article was originally published on The Conversation. Read the original article. Follow all of the Expert Voices issues and debates — and become part of the conversation — on Facebook, Twitter and Google +. The views expressed are those of the author and do not necessarily reflect the views of the publisher. This version of the article was originally published on Live Science.\n",
      "\n",
      "Prompt 1, Sequence 5: In the near future, humans and machines coexist in harmony, but that doesn't mean we won't have to work hard to make sure that doesn't happen.\n",
      "\n",
      "This article was originally published on The Conversation. Read the original article. Follow all of the Expert Voices issues and debates — and become part of the discussion — on Facebook, Twitter and Google +. The views expressed are those of the author and do not necessarily reflect the views of the publisher. This version of the article was originally published on Space.com.\n",
      "\n",
      "Prompt 2, Sequence 1: The year is 3020, and space exploration has reached new heights. The first human mission to Mars has been successfully completed, and humanity is on the cusp of colonizing the red planet.\n",
      "\n",
      "In the year 3020, the United States will be the first country to send a man to Mars.\n",
      "\n",
      "In the year 3020, the United States will be the first country to send a man to Mars.\n",
      "\n",
      "In the year 3020, the United States will be the first country to send a man to Mars.\n",
      "\n",
      "In the year 3020, the United States will be the first country to send a man to Mars.\n",
      "\n",
      "In the year 3020, the United States will be the first country to send a\n",
      "\n",
      "Prompt 2, Sequence 2: The year is 3020, and space exploration has reached new heights. The first human mission to Mars has been successfully completed, and humanity is on the cusp of colonizing the red planet.\n",
      "\n",
      "In the year 3020, the United States will be the first country to send a manned mission to Mars.\n",
      "\n",
      "In the year 3020, the United States will be the first country to send a manned mission to Mars.\n",
      "\n",
      "In the year 3020, the United States will be the first country to send a manned mission to Mars.\n",
      "\n",
      "In the year 3020, the United States will be the first country to send a manned mission to Mars.\n",
      "\n",
      "In the year 3020, the United States will be the first\n",
      "\n",
      "Prompt 2, Sequence 3: The year is 3020, and space exploration has reached new heights. The first human mission to Mars has been successfully completed, and humanity is on the cusp of colonizing the red planet.\n",
      "\n",
      "In the year 3020, the United States will be the first country to send a manned mission to Mars.\n",
      "\n",
      "In the year 3020, the United States will be the first country to send a manned mission to Mars. In the year 3020, the United States will be the first country to send a manned mission to Mars. In the year 3020, the United States will be the first country to send a manned mission to Mars. In the year 3020, the United States will be the first country to send a manned mission\n",
      "\n",
      "Prompt 2, Sequence 4: The year is 3020, and space exploration has reached new heights. The first human mission to Mars has been successfully completed, and humanity is on the cusp of colonizing the red planet.\n",
      "\n",
      "In the year 3020, the United States will be the first country to send a manned mission to Mars.\n",
      "\n",
      "In the year 3020, the United States will be the first country to send a manned mission to Mars.\n",
      "\n",
      "The year is 3020, and space exploration has reached new heights. The first human mission to Mars has been successfully completed, and humanity is on the cusp of colonizing the red planet.\n",
      "\n",
      "In the year 3020, the United States will be the first country to send a manned mission to\n",
      "\n",
      "Prompt 2, Sequence 5: The year is 3020, and space exploration has reached new heights. The first human mission to Mars has been successfully completed, and humanity is on the cusp of colonizing the red planet.\n",
      "\n",
      "In the year 3020, the United States will be the first country to send a manned mission to Mars.\n",
      "\n",
      "In the year 3020, the United States will be the first country to send a manned mission to Mars.\n",
      "\n",
      "In the year 3020, the United States will be the first country to send a manned mission to Mars.\n",
      "\n",
      "In the year 3020, the United States will be the first country to send a manned mission to Mars.\n",
      "\n",
      "The year is 3020, and space exploration has reached new heights\n",
      "\n",
      "Prompt 3, Sequence 1: With the rise of quantum computing, it is becoming more and more likely that we will be able to use quantum computers to solve some of the most difficult problems in science and engineering.\n",
      "\n",
      "Quantum computers are capable of solving problems that are impossible to solve using conventional computers. For example, a quantum computer could be used to solve the problem of finding the shortest path between two points.\n",
      "\n",
      "In order to achieve this, a quantum computer needs to be able to perform calculations in a way that is completely different from conventional computers.\n",
      "\n",
      "This means that a quantum computer would need to be able to perform calculations in a way that is not possible with conventional computers.\n",
      "\n",
      "In order to achieve this, a quantum computer needs to be able to perform\n",
      "\n",
      "Prompt 3, Sequence 2: With the rise of quantum computing, it is becoming more and more likely that we will be able to use quantum computers to solve some of the most difficult problems in science and engineering.\n",
      "\n",
      "Quantum computers are capable of solving problems that are impossible to solve using conventional computers. For example, a quantum computer could be used to solve the problem of finding the shortest path between two points.\n",
      "\n",
      "In order to achieve this, a quantum computer needs to be able to perform calculations in a way that is completely different from conventional computers.\n",
      "\n",
      "This means that a quantum computer would need to be able to perform calculations in a way that is not possible with conventional computers.\n",
      "\n",
      "In order to achieve this, a quantum computer would need to be able to\n",
      "\n",
      "Prompt 3, Sequence 3: With the rise of quantum computing, it is becoming more and more likely that we will be able to use quantum computers to solve some of the most difficult problems in science and engineering.\n",
      "\n",
      "Quantum computers are capable of solving problems that are impossible to solve using conventional computers. For example, a quantum computer could be used to solve the problem of finding the shortest path between two points.\n",
      "\n",
      "In order to achieve this, a quantum computer needs to be able to perform calculations in a way that is completely different from conventional computers.\n",
      "\n",
      "This means that a quantum computer would need to be able to perform calculations in a way that is not possible with conventional computers.\n",
      "\n",
      "This means that a quantum computer would need to be able to perform calculations in\n",
      "\n",
      "Prompt 3, Sequence 4: With the rise of quantum computing, it is becoming more and more likely that we will be able to use quantum computers to solve some of the most difficult problems in science and engineering.\n",
      "\n",
      "Quantum computers are capable of solving problems that are impossible to solve using conventional computers. For example, a quantum computer could be used to solve the problem of finding the shortest path between two points.\n",
      "\n",
      "In order to achieve this, a quantum computer needs to be able to perform calculations in a way that is completely different from conventional computers.\n",
      "\n",
      "This means that a quantum computer would need to be able to perform calculations in a way that is not possible with conventional computers.\n",
      "\n",
      "In order to achieve this, a quantum computer would need to perform calculations in\n",
      "\n",
      "Prompt 3, Sequence 5: With the rise of quantum computing, it is becoming more and more likely that we will be able to use quantum computers to solve some of the most difficult problems in science and engineering.\n",
      "\n",
      "Quantum computers are capable of solving problems that are impossible to solve using conventional computers. For example, a quantum computer could be used to solve the problem of finding the shortest path between two points.\n",
      "\n",
      "In order to achieve this, a quantum computer needs to be able to perform calculations in a way that is completely different from conventional computers.\n",
      "\n",
      "This means that a quantum computer would need to be able to perform calculations in a way that is not possible with conventional computers.\n",
      "\n",
      "In order to do this, a quantum computer needs to be able to perform\n",
      "\n",
      "Prompt 4, Sequence 1: In an alternate reality where time travel is possible, it is possible to travel back in time and change the course of history.\n",
      "\n",
      "Contents show]\n",
      "\n",
      "History Edit\n",
      "\n",
      "In an alternate reality where time travel is possible, it is possible to travel back in time and change the course of history.\n",
      "\n",
      "In an alternate reality where time travel is possible, it is possible to travel back in time and change the course of history.\n",
      "\n",
      "In an alternate reality where time travel is possible, it is possible to travel back in time and change the course of history.\n",
      "\n",
      "In an alternate reality where time travel is possible, it is possible to travel back in time and change the course of history.\n",
      "\n",
      "In an alternate reality where time\n",
      "\n",
      "Prompt 4, Sequence 2: In an alternate reality where time travel is possible, it is possible to travel back in time and change the course of history.\n",
      "\n",
      "Contents show]\n",
      "\n",
      "History Edit\n",
      "\n",
      "In an alternate reality where time travel is possible, it is possible to travel back in time and change the course of history.\n",
      "\n",
      "In an alternate reality where time travel is possible, it is possible to travel back in time and change the course of history. In an alternate reality where time travel is possible, it is possible to travel back in time and change the course of history. In an alternate reality where time travel is possible, it is possible to travel back in time and change the course of history. In an alternate reality where time travel is possible, it is\n",
      "\n",
      "Prompt 4, Sequence 3: In an alternate reality where time travel is possible, it is possible to travel back in time and change the course of history.\n",
      "\n",
      "Contents show]\n",
      "\n",
      "History Edit\n",
      "\n",
      "In an alternate reality where time travel is possible, it is possible to travel back in time and change the course of history.\n",
      "\n",
      "In an alternate reality where time travel is possible, it is possible to travel back in time and change the course of history.\n",
      "\n",
      "In an alternate reality where time travel is possible, it is possible to travel back in time and change the course of history.\n",
      "\n",
      "In an alternate reality where time travel is possible, it is possible to travel back in time and change the course of history.\n",
      "\n",
      "In an alternate universe where time\n",
      "\n",
      "Prompt 4, Sequence 4: In an alternate reality where time travel is possible, it is possible to travel back in time and change the course of history.\n",
      "\n",
      "Contents show]\n",
      "\n",
      "History Edit\n",
      "\n",
      "In an alternate reality where time travel is possible, it is possible to travel back in time and change the course of history.\n",
      "\n",
      "In an alternate reality where time travel is possible, it is possible to travel back in time and change the course of history.\n",
      "\n",
      "In an alternate reality where time travel is possible, it is possible to travel back in time and change the course of history.\n",
      "\n",
      "In an alternate reality where time travel is possible, it is possible to travel back in time and change the course of history.\n",
      "\n",
      "In an alternate future where time\n",
      "\n",
      "Prompt 4, Sequence 5: In an alternate reality where time travel is possible, it is possible to travel back in time and change the course of history.\n",
      "\n",
      "Contents show]\n",
      "\n",
      "History Edit\n",
      "\n",
      "In an alternate reality where time travel is possible, it is possible to travel back in time and change the course of history.\n",
      "\n",
      "In an alternate reality where time travel is possible, it is possible to travel back in time and change the course of history.\n",
      "\n",
      "In an alternate reality where time travel is possible, it is possible to travel back in time and change the course of history.\n",
      "\n",
      "In an alternate reality where time travel is possible, it is possible to travel back in time and change the course of history.\n",
      "\n",
      "In an alternate reality where Time\n",
      "\n",
      "Prompt 5, Sequence 1: The discovery of a new planet has sparked international interest.\n",
      "\n",
      "Astronomers using the Hubble Space Telescope have discovered a new planet orbiting a sun-like star in the constellation Cygnus.\n",
      "\n",
      "The planet, named Kepler-186f, is about 1.5 times the size of Earth and orbits its star once every 2.5 days.\n",
      "\n",
      "It is the first planet found orbiting a sun-like star in the habitable zone of its host star.\n",
      "\n",
      "The discovery was made using the HARPS spectrograph on the European Southern Observatory's Very Large Telescope (VLT) in Chile.\n",
      "\n",
      "Kepler-186f is about 1.5 times the size of Earth and orbits its star once every 2.5 days\n",
      "\n",
      "Prompt 5, Sequence 2: The discovery of a new planet has sparked international interest.\n",
      "\n",
      "Astronomers using the Hubble Space Telescope have discovered a new planet orbiting a sun-like star in the constellation Cygnus.\n",
      "\n",
      "The planet, named Kepler-186f, is about 1.5 times the size of Earth and orbits its star once every 2.5 days.\n",
      "\n",
      "It is the first planet found orbiting a sun-like star in the habitable zone of its host star.\n",
      "\n",
      "The discovery was made using the HARPS spectrograph on the European Southern Observatory's Very Large Telescope (VLT) in Chile.\n",
      "\n",
      "Kepler-186f is the first planet found orbiting a sun-like star in the habitable zone of its host star.\n",
      "\n",
      "Prompt 5, Sequence 3: The discovery of a new planet has sparked international interest.\n",
      "\n",
      "Astronomers using the Hubble Space Telescope have discovered a new planet orbiting a sun-like star in the constellation Cygnus.\n",
      "\n",
      "The planet, named Kepler-186f, is about 1.5 times the size of Earth and orbits its star once every 2.5 days.\n",
      "\n",
      "It is the first planet found orbiting a sun-like star in the habitable zone of its host star.\n",
      "\n",
      "The discovery was made using the HARPS spectrograph on the European Southern Observatory's Very Large Telescope (VLT) in Chile.\n",
      "\n",
      "Kepler-186f is the first planet found orbiting a sun-like star in the habitable zone of its host star\n",
      "\n",
      "\n",
      "Prompt 5, Sequence 4: The discovery of a new planet has sparked international interest.\n",
      "\n",
      "Astronomers using the Hubble Space Telescope have discovered a new planet orbiting a sun-like star in the constellation Cygnus.\n",
      "\n",
      "The planet, named Kepler-186f, is about 1.5 times the size of Earth and orbits its star once every 2.5 days.\n",
      "\n",
      "It is the first planet found orbiting a sun-like star in the habitable zone of its host star.\n",
      "\n",
      "The discovery was made using the HARPS spectrograph on the European Southern Observatory's Very Large Telescope (VLT) in Chile.\n",
      "\n",
      "Kepler-186f is about 1.5 times the size of Earth and orbits its sun once every 2.5 days\n",
      "\n",
      "Prompt 5, Sequence 5: The discovery of a new planet has sparked international interest.\n",
      "\n",
      "Astronomers using the Hubble Space Telescope have discovered a new planet orbiting a sun-like star in the constellation Cygnus.\n",
      "\n",
      "The planet, named Kepler-186f, is about 1.5 times the size of Earth and orbits its star once every 2.5 days.\n",
      "\n",
      "It is the first planet found orbiting a sun-like star in the habitable zone of its host star.\n",
      "\n",
      "The discovery was made using the HARPS spectrograph on the European Southern Observatory's Very Large Telescope (VLT) in Chile.\n",
      "\n",
      "Kepler-186f is about 1.5 times the size of Earth and orbits its star once every two days\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, TextGenerationPipeline\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "# 加载模型和分词器\n",
    "model_name = \"gpt2-large\"  # 使用更大的模型\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# 将模型移动到GPU（如果可用）\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# 使用TextGenerationPipeline进行批量生成，适合超大规模生成\n",
    "generator = TextGenerationPipeline(model=model, tokenizer=tokenizer, device=0 if torch.cuda.is_available() else -1)\n",
    "\n",
    "batch_input_texts = [\n",
    "    \"In the near future, humans and machines coexist in harmony,\",\n",
    "    \"The year is 3020, and space exploration has reached new heights.\",\n",
    "    \"With the rise of quantum computing,\",\n",
    "    \"In an alternate reality where time travel is possible,\",\n",
    "    \"The discovery of a new planet has sparked international interest.\"\n",
    "]\n",
    "\n",
    "# 批量生成，使用Beam Search\n",
    "batch_output = generator(batch_input_texts, max_length=150, num_return_sequences=5, \n",
    "                         temperature=0.7, top_k=50, top_p=0.95, repetition_penalty=1.2,\n",
    "                         num_beams=5)  # 使用Beam Search，并设置num_beams\n",
    "\n",
    "# 打印批量生成的结果\n",
    "for i, outputs in enumerate(batch_output):\n",
    "    for j, output in enumerate(outputs):\n",
    "        print(f\"Prompt {i + 1}, Sequence {j + 1}: {output['generated_text']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生成的文章：\n",
      "写一篇关于人工智能对未来世界影响的简短文章：。\n",
      "The first step is to find the right place for you. The second one will be a bit more difficult, but it's not impossible! You can also use your own skills and experience in this area as well:\n",
      "\n",
      " (1) Find an appropriate location\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# 加载GPT-2模型和分词器\n",
    "model_name = \"gpt2\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# 将模型移动到GPU（如果可用）\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# 定义生成文本的函数\n",
    "def generate_article(prompt, max_length=1000):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        max_length=max_length,\n",
    "        temperature=0.7,  # 控制生成文本的随机性\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "        repetition_penalty=1.2,\n",
    "        no_repeat_ngram_size=2,  # 避免重复的n-gram\n",
    "        num_return_sequences=1\n",
    "    )\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "# 提示文本\n",
    "prompt = \"写一篇关于人工智能对未来世界影响的简短文章：\"\n",
    "\n",
    "# 生成文章\n",
    "article = generate_article(prompt, max_length=100)\n",
    "\n",
    "# 打印生成的文章\n",
    "print(\"生成的文章：\")\n",
    "print(article)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生成的文章：\n",
      "写 一 篇 关 于 人 工 智 能 对 未 来 世 界 影 响 的 简 短 文 章 ： 人 类 的 未 知 ， 是 由 于 自 然 选 择 的 失 误 。 人 们 在 进 化 过 程 中 ， 不 断 地 寻 找 新 的 生 命 体 ， 而 这 些 新 生 物 ， 正 是 我 们 所 需 要 的 。 《 人 猿 》 作 者 ： 刘 晓 博 出 版 社 ： 北 京 大 学 出 品 人 ： 王 小 波 译 者 简 介 ： 李 开 复 ， 美 国 著 名 科 幻 作 家 、 科 技 评 论 家 ， 曾 任 职 于 美 联 储 主 席 耶 伦 ， 现 为 美 股 市 场 研 究 员 。 他 的 作 品 被 称 为 人 性 的 弱 点 ， 也 被 认 为 是 科 学 与 艺 术 之 间 的 差 异 。 李 先 生 是 一 位 有 着 丰 富 经 验 和 深 厚 理 想 的 科 普 作 曲 家 。 在 他 看 来 ， 人 的 思 维 方 式 是 无 法 改 变 的 ， 因 此 ， 他 希 望 通 过 自 己 的 创 造 力 ， 让 更 多 的 人 了 解 人 ， 并 且 帮 助 他 们 成 长 。 作 为 一 个 科 研 人 员 ， 李 老 师 的 观 点 非 常 独 到 ， 从 他 对 人 脑 的 理 解 ， 到 对 科 教 领 域 的 探 索 ， 都 值 得 我 去 思 考 。 作 文 题 目 ： 《 你 的 梦 想 是 什 么 ？ 》 （ 作 ） 作 用 ： 引 导 读 者 从 心 理 学 角 度 分 析 人 与 人 之 交 往 的 本 质 ， 以 及 如 何 利 用 人 际 关 系 ， 建 立 人 格 。 文 中 提 到 的 你 是 指 人 在 面 临 困 境 时 ， 会 采 取 行 动 的 那 种 人 。 这 种 行 为 可 以 说 是 人 生 的 一 部 分 ， 它 包 括 了 人 对 事 情 的 态 度 ， 或 者 是 对 自 身 的 认 识 。 但 是 ， 这 样 的 行 径 却 是 不 合 适 的 ： 人 总 是 在 不 停 地 试 图 寻 求 解 决 问 题 的 办 法 ， 甚 至 是 逃 避 痛 苦 。 因 为 ， 当 你 发 现 自 已 的 存 在 感 受 到 了 压 力 时 就 会 产 生 焦 虑 ， 觉 得 自 我 的 价 值 不 够 高 昂 ， 就 像 是 被 抛 弃 了 一 样 。 而 人 只 是 把 自 尊 放 在 了 别 人 身 上 ， 把 责 任 推 给 了 自 私 的 自 负 。 所 以 ， 我 认 同 李 小 姐 的 做 法 。 我 相 信 ， 在 人 群 中 的 每 一 次 碰 撞 ， 每 个 人 都 会 有 自 卑 感 ， 但 我 始 终 坚 持 这 一 点 。 当 我 看 到 一 些 人 抱 怨 自 杀 的 时 候 ， 其 实 我 很 清 楚 ， 自 救 的 意 义 远 比 自 残 的 重 要 。 如 果 你 真 的 想 要 自 保 ， 请 记 住 ， 你 永 远 不 会 知 道 自 欺 欺 人 是 怎 么 回 事 。 你 必 须 要 明 白 ， 如 今 的 社 会 ， 没 有 谁 愿 意 承 担 责 骂 ， 谁 又 愿 冒 风 险 去 拯 救 你 呢? 所 谓 的 救 赎 ， 只 不 过 是 为 了 让 你 自 由 地 活 下 去 罢 了 。 《 我 是 谁 》 是 李 克 强 总 理 在 2015 年 3 月 份 的 演 讲 稿 ， 讲 述 了 他 在 中 央 政 治 局 第 二 十 八 次 集 体 学 习 时 的 故 事 ， 内 容 涉 及 到 人 口 老 龄 化 、 城 镇 化 等 问 答 。 该 书 的 主 旨 是 ： 我 要 告 诉 大 家 的 是 : 人 民 币 汇 率 的 走 势 ， 绝 不 是 单 边 贬 值 ， 更 不 应 该 是 双 向 浮 动 。 即 使 人 均 gdp 增 速 降 低 ， 汇 兑 损 失 也 会 减 少 ， 最 终 还 是 会 出 现 资 金 外 流 。 不 管 是 哪 一 种 货 币 ， 一 定 要 保 持 人 币 的 稳 定 ， 否 则 ， 将 会 陷 入 贬 损 。 中 国 的 经 济 结 构 调 整 ， 必 然 会 带 来 一 系 列 的 问 号 。 一 旦 人 人 皆 可 拥 有 一 张 银 行 卡 ， 那 么 ， 全 球 各 国 都 将 面 对 一 场 危 机 。 对 于 中 产 阶 级 而 言 ， 拥 抱 人 权 ， 享 受 人 间 天 堂 ， 才 是 最 好 的 选 项 。 （ 本 文 转 载 自 网 络 ， 若 侵 权 请 后 台 联 系 删 除 ） 猜 你 喜 欢 【 1 】 一 条\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, BertTokenizer\n",
    "\n",
    "# 加载中文的GPT-2模型和分词器\n",
    "model_name = \"uer/gpt2-chinese-cluecorpussmall\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# 将模型移动到GPU（如果可用）\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# 定义生成文本的函数\n",
    "def generate_article(prompt, max_length=1000):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        max_length=max_length,\n",
    "        temperature=0.7,  # 控制生成文本的随机性\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "        repetition_penalty=1.2,\n",
    "        no_repeat_ngram_size=2,  # 避免重复的n-gram\n",
    "        num_return_sequences=1\n",
    "    )\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "# 提示文本\n",
    "prompt = \"写一篇关于人工智能对未来世界影响的简短文章：\"\n",
    "\n",
    "# 生成文章\n",
    "article = generate_article(prompt, max_length=1000)\n",
    "\n",
    "# 打印生成的文章\n",
    "print(\"生成的文章：\")\n",
    "print(article)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生成的文章：\n",
      "写 一 篇 关 于 人 工 智 能 对 未 来 世 界 影 响 的 简 短 文 章 ： 人 类 的 未 知 ， 是 由 于 自 然 选 择 的 失 误 。\n",
      " 人 \n",
      "未 来 世 界 影 响 的 简 短 文 章 ： 人 类 的 未 知 ， 是 由 于 自 然 选 择 的 失 误 。\n",
      " 人 们 在 进 化 过 程 中 ， 不 断 \n",
      "章 ： 人 类 的 未 知 ， 是 由 于 自 然 选 择 的 失 误 。\n",
      " 人 们 在 进 化 过 程 中 ， 不 断 地 寻 找 新 的 生 命 体 ， 而 \n",
      "于 自 然 选 择 的 失 误 。\n",
      " 人 们 在 进 化 过 程 中 ， 不 断 地 寻 找 新 的 生 命 体 ， 而 这 些 新 生 物 ， 正 是 我 们 \n",
      "们 在 进 化 过 程 中 ， 不 断 地 寻 找 新 的 生 命 体 ， 而 这 些 新 生 物 ， 正 是 我 们 所 需 要 的 。\n",
      " 《 人 猿 》 作 \n",
      "地 寻 找 新 的 生 命 体 ， 而 这 些 新 生 物 ， 正 是 我 们 所 需 要 的 。\n",
      " 《 人 猿 》 作 者 ： 刘 晓 博 出 版 社 ： 北 \n",
      "这 些 新 生 物 ， 正 是 我 们 所 需 要 的 。\n",
      " 《 人 猿 》 作 者 ： 刘 晓 博 出 版 社 ： 北 京 大 学 出 品 人 ： 王 小 波 \n",
      "所 需 要 的 。\n",
      " 《 人 猿 》 作 者 ： 刘 晓 博 出 版 社 ： 北 京 大 学 出 品 人 ： 王 小 波 译 者 简 介 ： 李 开 复 ， 美 \n",
      "者 ： 刘 晓 博 出 版 社 ： 北 京 大 学 出 品 人 ： 王 小 波 译 者 简 介 ： 李 开 复 ， 美 国 著 名 科 幻 作 家 、 科 技 \n",
      "京 大 学 出 品 人 ： 王 小 波 译 者 简 介 ： 李 开 复 ， 美 国 著 名 科 幻 作 家 、 科 技 评 论 家 ， 曾 任 职 于 美 联 \n",
      "译 者 简 介 ： 李 开 复 ， 美 国 著 名 科 幻 作 家 、 科 技 评 论 家 ， 曾 任 职 于 美 联 储 主 席 耶 伦 ， 现 为 美 股 \n",
      "国 著 名 科 幻 作 家 、 科 技 评 论 家 ， 曾 任 职 于 美 联 储 主 席 耶 伦 ， 现 为 美 股 市 场 研 究 员 。\n",
      " 他 的 作 品 \n",
      "评 论 家 ， 曾 任 职 于 美 联 储 主 席 耶 伦 ， 现 为 美 股 市 场 研 究 员 。\n",
      " 他 的 作 品 被 称 为 人 性 的 弱 点 ， 也 \n",
      "储 主 席 耶 伦 ， 现 为 美 股 市 场 研 究 员 。\n",
      " 他 的 作 品 被 称 为 人 性 的 弱 点 ， 也 被 认 为 是 科 学 与 艺 术 之 \n",
      "市 场 研 究 员 。\n",
      " 他 的 作 品 被 称 为 人 性 的 弱 点 ， 也 被 认 为 是 科 学 与 艺 术 之 间 的 差 异 。\n",
      " 李 先 生 是 一 \n",
      "被 称 为 人 性 的 弱 点 ， 也 被 认 为 是 科 学 与 艺 术 之 间 的 差 异 。\n",
      " 李 先 生 是 一 位 有 着 丰 富 经 验 和 深 厚 \n",
      "被 认 为 是 科 学 与 艺 术 之 间 的 差 异 。\n",
      " 李 先 生 是 一 位 有 着 丰 富 经 验 和 深 厚 理 想 的 科 普 作 曲 家 。\n",
      " 在 \n",
      "间 的 差 异 。\n",
      " 李 先 生 是 一 位 有 着 丰 富 经 验 和 深 厚 理 想 的 科 普 作 曲 家 。\n",
      " 在 他 看 来 ， 人 的 思 维 方 式 \n",
      "位 有 着 丰 富 经 验 和 深 厚 理 想 的 科 普 作 曲 家 。\n",
      " 在 他 看 来 ， 人 的 思 维 方 式 是 无 法 改 变 的 ， 因 此 ， \n",
      "理 想 的 科 普 作 曲 家 。\n",
      " 在 他 看 来 ， 人 的 思 维 方 式 是 无 法 改 变 的 ， 因 此 ， 他 希 望 通 过 自 己 的 创 造 \n",
      "他 看 来 ， 人 的 思 维 方 式 是 无 法 改 变 的 ， 因 此 ， 他 希 望 通 过 自 己 的 创 造 力 ， 让 更 多 的 人 了 解 人 \n",
      "是 无 法 改 变 的 ， 因 此 ， 他 希 望 通 过 自 己 的 创 造 力 ， 让 更 多 的 人 了 解 人 ， 并 且 帮 助 他 们 成 长 。\n",
      " \n",
      "他 希 望 通 过 自 己 的 创 造 力 ， 让 更 多 的 人 了 解 人 ， 并 且 帮 助 他 们 成 长 。\n",
      " 作 为 一 个 科 研 人 员 ， 李 \n",
      "力 ， 让 更 多 的 人 了 解 人 ， 并 且 帮 助 他 们 成 长 。\n",
      " 作 为 一 个 科 研 人 员 ， 李 老 师 的 观 点 非 常 独 到 ， \n",
      "， 并 且 帮 助 他 们 成 长 。\n",
      " 作 为 一 个 科 研 人 员 ， 李 老 师 的 观 点 非 常 独 到 ， 从 他 对 人 脑 的 理 解 ， 到 \n",
      "作 为 一 个 科 研 人 员 ， 李 老 师 的 观 点 非 常 独 到 ， 从 他 对 人 脑 的 理 解 ， 到 对 科 教 领 域 的 探 索 ， 都 \n",
      "老 师 的 观 点 非 常 独 到 ， 从 他 对 人 脑 的 理 解 ， 到 对 科 教 领 域 的 探 索 ， 都 值 得 我 去 思 考 。\n",
      " 作 文 题 \n",
      "从 他 对 人 脑 的 理 解 ， 到 对 科 教 领 域 的 探 索 ， 都 值 得 我 去 思 考 。\n",
      " 作 文 题 目 ： 《 你 的 梦 想 是 什 么 \n",
      "对 科 教 领 域 的 探 索 ， 都 值 得 我 去 思 考 。\n",
      " 作 文 题 目 ： 《 你 的 梦 想 是 什 么 ？\n",
      " 》 （ 作 ） 作 用 ： 引 导 \n",
      "值 得 我 去 思 考 。\n",
      " 作 文 题 目 ： 《 你 的 梦 想 是 什 么 ？\n",
      " 》 （ 作 ） 作 用 ： 引 导 读 者 从 心 理 学 角 度 分 析 \n",
      "目 ： 《 你 的 梦 想 是 什 么 ？\n",
      " 》 （ 作 ） 作 用 ： 引 导 读 者 从 心 理 学 角 度 分 析 人 与 人 之 交 往 的 本 质 ， \n",
      "？\n",
      " 》 （ 作 ） 作 用 ： 引 导 读 者 从 心 理 学 角 度 分 析 人 与 人 之 交 往 的 本 质 ， 以 及 如 何 利 用 人 际 关 系 \n",
      "读 者 从 心 理 学 角 度 分 析 人 与 人 之 交 往 的 本 质 ， 以 及 如 何 利 用 人 际 关 系 ， 建 立 人 格 。\n",
      " 文 中 提 到 \n",
      "人 与 人 之 交 往 的 本 质 ， 以 及 如 何 利 用 人 际 关 系 ， 建 立 人 格 。\n",
      " 文 中 提 到 的 你 是 指 人 在 面 临 困 境 \n",
      "以 及 如 何 利 用 人 际 关 系 ， 建 立 人 格 。\n",
      " 文 中 提 到 的 你 是 指 人 在 面 临 困 境 时 ， 会 采 取 行 动 的 那 种 \n",
      "， 建 立 人 格 。\n",
      " 文 中 提 到 的 你 是 指 人 在 面 临 困 境 时 ， 会 采 取 行 动 的 那 种 人 。\n",
      " 这 种 行 为 可 以 说 是 \n",
      "的 你 是 指 人 在 面 临 困 境 时 ， 会 采 取 行 动 的 那 种 人 。\n",
      " 这 种 行 为 可 以 说 是 人 生 的 一 部 分 ， 它 包 括 \n",
      "时 ， 会 采 取 行 动 的 那 种 人 。\n",
      " 这 种 行 为 可 以 说 是 人 生 的 一 部 分 ， 它 包 括 了 人 对 事 情 的 态 度 ， 或 \n",
      "人 。\n",
      " 这 种 行 为 可 以 说 是 人 生 的 一 部 分 ， 它 包 括 了 人 对 事 情 的 态 度 ， 或 者 是 对 自 身 的 认 识 。\n",
      " 但 \n",
      "人 生 的 一 部 分 ， 它 包 括 了 人 对 事 情 的 态 度 ， 或 者 是 对 自 身 的 认 识 。\n",
      " 但 是 ， 这 样 的 行 径 却 是 不 \n",
      "了 人 对 事 情 的 态 度 ， 或 者 是 对 自 身 的 认 识 。\n",
      " 但 是 ， 这 样 的 行 径 却 是 不 合 适 的 ： 人 总 是 在 不 停 \n",
      "者 是 对 自 身 的 认 识 。\n",
      " 但 是 ， 这 样 的 行 径 却 是 不 合 适 的 ： 人 总 是 在 不 停 地 试 图 寻 求 解 决 问 题 的 \n",
      "是 ， 这 样 的 行 径 却 是 不 合 适 的 ： 人 总 是 在 不 停 地 试 图 寻 求 解 决 问 题 的 办 法 ， 甚 至 是 逃 避 痛 苦 \n",
      "合 适 的 ： 人 总 是 在 不 停 地 试 图 寻 求 解 决 问 题 的 办 法 ， 甚 至 是 逃 避 痛 苦 。\n",
      " 因 为 ， 当 你 发 现 自 已 \n",
      "地 试 图 寻 求 解 决 问 题 的 办 法 ， 甚 至 是 逃 避 痛 苦 。\n",
      " 因 为 ， 当 你 发 现 自 已 的 存 在 感 受 到 了 压 力 时 \n",
      "办 法 ， 甚 至 是 逃 避 痛 苦 。\n",
      " 因 为 ， 当 你 发 现 自 已 的 存 在 感 受 到 了 压 力 时 就 会 产 生 焦 虑 ， 觉 得 自 \n",
      "。\n",
      " 因 为 ， 当 你 发 现 自 已 的 存 在 感 受 到 了 压 力 时 就 会 产 生 焦 虑 ， 觉 得 自 我 的 价 值 不 够 高 昂 ， 就 \n",
      "的 存 在 感 受 到 了 压 力 时 就 会 产 生 焦 虑 ， 觉 得 自 我 的 价 值 不 够 高 昂 ， 就 像 是 被 抛 弃 了 一 样 。\n",
      " 而 \n",
      "就 会 产 生 焦 虑 ， 觉 得 自 我 的 价 值 不 够 高 昂 ， 就 像 是 被 抛 弃 了 一 样 。\n",
      " 而 人 只 是 把 自 尊 放 在 了 别 \n",
      "我 的 价 值 不 够 高 昂 ， 就 像 是 被 抛 弃 了 一 样 。\n",
      " 而 人 只 是 把 自 尊 放 在 了 别 人 身 上 ， 把 责 任 推 给 了 \n",
      "像 是 被 抛 弃 了 一 样 。\n",
      " 而 人 只 是 把 自 尊 放 在 了 别 人 身 上 ， 把 责 任 推 给 了 自 私 的 自 负 。\n",
      " 所 以 ， 我 \n",
      "人 只 是 把 自 尊 放 在 了 别 人 身 上 ， 把 责 任 推 给 了 自 私 的 自 负 。\n",
      " 所 以 ， 我 认 同 李 小 姐 的 做 法 。\n",
      " 我 \n",
      "人 身 上 ， 把 责 任 推 给 了 自 私 的 自 负 。\n",
      " 所 以 ， 我 认 同 李 小 姐 的 做 法 。\n",
      " 我 相 信 ， 在 人 群 中 的 每 一 \n",
      "自 私 的 自 负 。\n",
      " 所 以 ， 我 认 同 李 小 姐 的 做 法 。\n",
      " 我 相 信 ， 在 人 群 中 的 每 一 次 碰 撞 ， 每 个 人 都 会 有 \n",
      "认 同 李 小 姐 的 做 法 。\n",
      " 我 相 信 ， 在 人 群 中 的 每 一 次 碰 撞 ， 每 个 人 都 会 有 自 卑 感 ， 但 我 始 终 坚 持 \n",
      "相 信 ， 在 人 群 中 的 每 一 次 碰 撞 ， 每 个 人 都 会 有 自 卑 感 ， 但 我 始 终 坚 持 这 一 点 。\n",
      " 当 我 看 到 一 些 \n",
      "次 碰 撞 ， 每 个 人 都 会 有 自 卑 感 ， 但 我 始 终 坚 持 这 一 点 。\n",
      " 当 我 看 到 一 些 人 抱 怨 自 杀 的 时 候 ， 其 \n",
      "自 卑 感 ， 但 我 始 终 坚 持 这 一 点 。\n",
      " 当 我 看 到 一 些 人 抱 怨 自 杀 的 时 候 ， 其 实 我 很 清 楚 ， 自 救 的 意 \n",
      "这 一 点 。\n",
      " 当 我 看 到 一 些 人 抱 怨 自 杀 的 时 候 ， 其 实 我 很 清 楚 ， 自 救 的 意 义 远 比 自 残 的 重 要 。\n",
      " 如 \n",
      "人 抱 怨 自 杀 的 时 候 ， 其 实 我 很 清 楚 ， 自 救 的 意 义 远 比 自 残 的 重 要 。\n",
      " 如 果 你 真 的 想 要 自 保 ， 请 \n",
      "实 我 很 清 楚 ， 自 救 的 意 义 远 比 自 残 的 重 要 。\n",
      " 如 果 你 真 的 想 要 自 保 ， 请 记 住 ， 你 永 远 不 会 知 道 \n",
      "义 远 比 自 残 的 重 要 。\n",
      " 如 果 你 真 的 想 要 自 保 ， 请 记 住 ， 你 永 远 不 会 知 道 自 欺 欺 人 是 怎 么 回 事 。\n",
      " \n",
      "果 你 真 的 想 要 自 保 ， 请 记 住 ， 你 永 远 不 会 知 道 自 欺 欺 人 是 怎 么 回 事 。\n",
      " 你 必 须 要 明 白 ， 如 今 的 \n",
      "记 住 ， 你 永 远 不 会 知 道 自 欺 欺 人 是 怎 么 回 事 。\n",
      " 你 必 须 要 明 白 ， 如 今 的 社 会 ， 没 有 谁 愿 意 承 担 \n",
      "自 欺 欺 人 是 怎 么 回 事 。\n",
      " 你 必 须 要 明 白 ， 如 今 的 社 会 ， 没 有 谁 愿 意 承 担 责 骂 ， 谁 又 愿 冒 风 险 去 \n",
      "你 必 须 要 明 白 ， 如 今 的 社 会 ， 没 有 谁 愿 意 承 担 责 骂 ， 谁 又 愿 冒 风 险 去 拯 救 你 呢? 所 谓 的 救 赎 ，\n",
      "社 会 ， 没 有 谁 愿 意 承 担 责 骂 ， 谁 又 愿 冒 风 险 去 拯 救 你 呢? 所 谓 的 救 赎 ， 只 不 过 是 为 了 让 你 自 由\n",
      "责 骂 ， 谁 又 愿 冒 风 险 去 拯 救 你 呢? 所 谓 的 救 赎 ， 只 不 过 是 为 了 让 你 自 由 地 活 下 去 罢 了 。\n",
      " 《 我 是\n",
      "拯 救 你 呢? 所 谓 的 救 赎 ， 只 不 过 是 为 了 让 你 自 由 地 活 下 去 罢 了 。\n",
      " 《 我 是 谁 》 是 李 克 强 总 理 在 2\n",
      " 只 不 过 是 为 了 让 你 自 由 地 活 下 去 罢 了 。\n",
      " 《 我 是 谁 》 是 李 克 强 总 理 在 2015 年 3 月 份 的 演 讲 稿 \n",
      " 地 活 下 去 罢 了 。\n",
      " 《 我 是 谁 》 是 李 克 强 总 理 在 2015 年 3 月 份 的 演 讲 稿 ， 讲 述 了 他 在 中 央 政 治 \n",
      " 谁 》 是 李 克 强 总 理 在 2015 年 3 月 份 的 演 讲 稿 ， 讲 述 了 他 在 中 央 政 治 局 第 二 十 八 次 集 体 学 习 \n",
      "015 年 3 月 份 的 演 讲 稿 ， 讲 述 了 他 在 中 央 政 治 局 第 二 十 八 次 集 体 学 习 时 的 故 事 ， 内 容 涉 及 到 \n",
      "， 讲 述 了 他 在 中 央 政 治 局 第 二 十 八 次 集 体 学 习 时 的 故 事 ， 内 容 涉 及 到 人 口 老 龄 化 、 城 镇 化 等 \n",
      "局 第 二 十 八 次 集 体 学 习 时 的 故 事 ， 内 容 涉 及 到 人 口 老 龄 化 、 城 镇 化 等 问 答 。\n",
      " 该 书 的 主 旨 是 ： \n",
      "时 的 故 事 ， 内 容 涉 及 到 人 口 老 龄 化 、 城 镇 化 等 问 答 。\n",
      " 该 书 的 主 旨 是 ： 我 要 告 诉 大 家 的 是 : 人 \n",
      "人 口 老 龄 化 、 城 镇 化 等 问 答 。\n",
      " 该 书 的 主 旨 是 ： 我 要 告 诉 大 家 的 是 : 人 民 币 汇 率 的 走 势 ， 绝 不 \n",
      "问 答 。\n",
      " 该 书 的 主 旨 是 ： 我 要 告 诉 大 家 的 是 : 人 民 币 汇 率 的 走 势 ， 绝 不 是 单 边 贬 值 ， 更 不 应 该 \n",
      "我 要 告 诉 大 家 的 是 : 人 民 币 汇 率 的 走 势 ， 绝 不 是 单 边 贬 值 ， 更 不 应 该 是 双 向 浮 动 。\n",
      " 即 使 人 均 \n",
      "民 币 汇 率 的 走 势 ， 绝 不 是 单 边 贬 值 ， 更 不 应 该 是 双 向 浮 动 。\n",
      " 即 使 人 均 gdp 增 速 降 低 ， 汇 兑 损 \n",
      "是 单 边 贬 值 ， 更 不 应 该 是 双 向 浮 动 。\n",
      " 即 使 人 均 gdp 增 速 降 低 ， 汇 兑 损 失 也 会 减 少 ， 最 终 还 是 \n",
      "是 双 向 浮 动 。\n",
      " 即 使 人 均 gdp 增 速 降 低 ， 汇 兑 损 失 也 会 减 少 ， 最 终 还 是 会 出 现 资 金 外 流 。\n",
      " 不 管 \n",
      "gdp 增 速 降 低 ， 汇 兑 损 失 也 会 减 少 ， 最 终 还 是 会 出 现 资 金 外 流 。\n",
      " 不 管 是 哪 一 种 货 币 ， 一 定 要 \n",
      "失 也 会 减 少 ， 最 终 还 是 会 出 现 资 金 外 流 。\n",
      " 不 管 是 哪 一 种 货 币 ， 一 定 要 保 持 人 币 的 稳 定 ， 否 则 \n",
      "会 出 现 资 金 外 流 。\n",
      " 不 管 是 哪 一 种 货 币 ， 一 定 要 保 持 人 币 的 稳 定 ， 否 则 ， 将 会 陷 入 贬 损 。\n",
      " 中 国 \n",
      "是 哪 一 种 货 币 ， 一 定 要 保 持 人 币 的 稳 定 ， 否 则 ， 将 会 陷 入 贬 损 。\n",
      " 中 国 的 经 济 结 构 调 整 ， 必 然 \n",
      "保 持 人 币 的 稳 定 ， 否 则 ， 将 会 陷 入 贬 损 。\n",
      " 中 国 的 经 济 结 构 调 整 ， 必 然 会 带 来 一 系 列 的 问 号 。\n",
      " \n",
      "， 将 会 陷 入 贬 损 。\n",
      " 中 国 的 经 济 结 构 调 整 ， 必 然 会 带 来 一 系 列 的 问 号 。\n",
      " 一 旦 人 人 皆 可 拥 有 一 张 \n",
      "的 经 济 结 构 调 整 ， 必 然 会 带 来 一 系 列 的 问 号 。\n",
      " 一 旦 人 人 皆 可 拥 有 一 张 银 行 卡 ， 那 么 ， 全 球 各 \n",
      "会 带 来 一 系 列 的 问 号 。\n",
      " 一 旦 人 人 皆 可 拥 有 一 张 银 行 卡 ， 那 么 ， 全 球 各 国 都 将 面 对 一 场 危 机 。\n",
      " \n",
      "一 旦 人 人 皆 可 拥 有 一 张 银 行 卡 ， 那 么 ， 全 球 各 国 都 将 面 对 一 场 危 机 。\n",
      " 对 于 中 产 阶 级 而 言 ， 拥 \n",
      "银 行 卡 ， 那 么 ， 全 球 各 国 都 将 面 对 一 场 危 机 。\n",
      " 对 于 中 产 阶 级 而 言 ， 拥 抱 人 权 ， 享 受 人 间 天 堂 \n",
      "国 都 将 面 对 一 场 危 机 。\n",
      " 对 于 中 产 阶 级 而 言 ， 拥 抱 人 权 ， 享 受 人 间 天 堂 ， 才 是 最 好 的 选 项 。\n",
      " （ \n",
      "对 于 中 产 阶 级 而 言 ， 拥 抱 人 权 ， 享 受 人 间 天 堂 ， 才 是 最 好 的 选 项 。\n",
      " （ 本 文 转 载 自 网 络 ， 若 侵 \n",
      "抱 人 权 ， 享 受 人 间 天 堂 ， 才 是 最 好 的 选 项 。\n",
      " （ 本 文 转 载 自 网 络 ， 若 侵 权 请 后 台 联 系 删 除 ） 猜 \n",
      "， 才 是 最 好 的 选 项 。\n",
      " （ 本 文 转 载 自 网 络 ， 若 侵 权 请 后 台 联 系 删 除 ） 猜 你 喜 欢 【 1 】 一 条\n",
      "本 文 转 载 自 网 络 ， 若 侵 权 请 后 台 联 系 删 除 ） 猜 你 喜 欢 【 1 】 一 条\n",
      "权 请 后 台 联 系 删 除 ） 猜 你 喜 欢 【 1 】 一 条\n",
      "你 喜 欢 【 1 】 一 条。\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, BertTokenizer\n",
    "import re\n",
    "\n",
    "# 加载中文的GPT-2模型和分词器\n",
    "model_name = \"uer/gpt2-chinese-cluecorpussmall\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# 将模型移动到GPU（如果可用）\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# 定义生成文本的函数\n",
    "def generate_article(prompt, max_length=10000):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        max_length=max_length,\n",
    "        temperature=0.7,  # 控制生成文本的随机性\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "        repetition_penalty=1.2,\n",
    "        no_repeat_ngram_size=2,  # 避免重复的n-gram\n",
    "        num_return_sequences=1\n",
    "    )\n",
    "    text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return format_article(text)\n",
    "\n",
    "# 定义文本格式化的函数\n",
    "def format_article(text):\n",
    "    # 根据20个字添加换行符\n",
    "    formatted_text = \"\\n\".join([text[i:i+80] for i in range(0, len(text), 20)])\n",
    "    \n",
    "    # 简单的标点符号修饰：在每个句子结尾添加句号\n",
    "    formatted_text = re.sub(r'([。！？])', r'\\1\\n', formatted_text)  # 在句号、感叹号、问号后换行\n",
    "    formatted_text = re.sub(r'([^。！？])$', r'\\1。', formatted_text)  # 如果结尾没有标点，添加句号\n",
    "    return formatted_text\n",
    "\n",
    "# 提示文本\n",
    "prompt = \"写一篇关于人工智能对未来世界影响的简短文章：\"\n",
    "\n",
    "# 生成文章\n",
    "article = generate_article(prompt, max_length=1000)\n",
    "\n",
    "# 打印生成的文章\n",
    "print(\"生成的文章：\")\n",
    "print(article)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /var/folders/mm/885dzr5d6s37b6tphkxb241c0000gn/T/jieba.cache\n",
      "Loading model cost 0.565 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生成的文章：\n",
      "写 一 篇 关 于 人 工 智 能 对 \n",
      "未 来 世 界 影 响 的 简 短 文 \n",
      "章 ： 人 类 的 未 知 ， 是 由 \n",
      "于 自 然 选 择 的 失 误 。\n",
      " 人 们 在 进 化 过 程 中 ， 不\n",
      " 断 地 寻 找 新 的 生 命 体 ，\n",
      " 而 这 些 新 生 物 ， 正 是 我\n",
      " 们 所 需 要 的 。\n",
      " 《 人 猿 》 作 者 ： 刘 晓 博\n",
      " 出 版 社 ： 北 京 大 学 出 品\n",
      " 人 ： 王 小 波 译 者 简 介 ：\n",
      " 李 开 复 ， 美 国 著 名 科 幻\n",
      " 作 家 、 科 技 评 论 家 ， 曾\n",
      " 任 职 于 美 联 储 主 席 耶 伦\n",
      " ， 现 为 美 股 市 场 研 究 员\n",
      " 。 他 的 作 品 被 称 为 人 性\n",
      " 的 弱 点 ， 也 被 认 为 是 科\n",
      " 学 与 艺 术 之 间 的 差 异 。\n",
      " 李 先 生 是 一 位 有 着 丰 富\n",
      " 经 验 和 深 厚 理 想。\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, BertTokenizer\n",
    "import jieba\n",
    "import re\n",
    "\n",
    "# 加载中文的GPT-2模型和分词器\n",
    "model_name = \"uer/gpt2-chinese-cluecorpussmall\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# 将模型移动到GPU（如果可用）\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# 定义生成文本的函数\n",
    "def generate_article(prompt, max_length=100):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        max_length=max_length,\n",
    "        temperature=0.7,  # 控制生成文本的随机性\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "        repetition_penalty=1.2,\n",
    "        no_repeat_ngram_size=2,  # 避免重复的n-gram\n",
    "        num_return_sequences=1\n",
    "    )\n",
    "    text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return format_article(text)\n",
    "\n",
    "# 定义文本格式化的函数\n",
    "def format_article(text):\n",
    "    # 使用jieba进行分词\n",
    "    words = jieba.lcut(text)\n",
    "    \n",
    "    # 动态换行：每行尽量保证一个完整的短句（5到20个字符之间）\n",
    "    formatted_lines = []\n",
    "    current_line = \"\"\n",
    "    \n",
    "    for word in words:\n",
    "        current_line += word\n",
    "        if len(current_line) >= 20 or (len(current_line) >= 5 and re.match(r'[。！？]', word)):\n",
    "            formatted_lines.append(current_line)\n",
    "            current_line = \"\"\n",
    "    \n",
    "    if current_line:\n",
    "        formatted_lines.append(current_line)\n",
    "    \n",
    "    # 标点符号处理\n",
    "    formatted_text = \"\\n\".join(formatted_lines)\n",
    "    formatted_text = re.sub(r'([^。！？])$', r'\\1。', formatted_text)  # 如果结尾没有标点，添加句号\n",
    "    \n",
    "    return formatted_text\n",
    "\n",
    "# 提示文本\n",
    "prompt = \"写一篇关于人工智能对未来世界影响的简短文章：\"\n",
    "\n",
    "# 生成文章\n",
    "article = generate_article(prompt, max_length=200)\n",
    "\n",
    "# 打印生成的文章\n",
    "print(\"生成的文章：\")\n",
    "print(article)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生成的文章：\n",
      "写  一  篇  关  于  人  工  智  能  对  未  来  世  界  影  响  的  简  短  文  章  ：  人  类  的  未  知  ，  是  由  于  自  然  选  择  的  失  误  。\n",
      "  人  们  在  进  化  过  程  中  ，  不  断  地  寻  找  新  的  生  命  体  ，  而  这  些  新  生  物  ，  正  是  我  们  所  需  要  的  。\n",
      "  《  人  猿  》  作  者  ：  刘  晓  博  出  版  社  ：  北  京  大  学  出  品  人  ：  王  小  波  译  者  简  介  ：  李  开  复  ，  美  国  著  名  科  幻  作  家  、  科  技  评  论  家  ，  曾  任  职  于  美  联  储  主  席  耶  伦  ，  现  为  美  股  市  场  研  究  员  。\n",
      "  他  的  作  品  被  称  为  人  性  的  弱  点  ，  也  被  认  为  是  科  学  与  艺  术  之  间  的  差  异  。\n",
      "  李  先  生  是  一  位  有  着  丰  富  经  验  和  深  厚  理  想。\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, BertTokenizer\n",
    "import jieba\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "# 加载中文的GPT-2模型和分词器\n",
    "model_name = \"uer/gpt2-chinese-cluecorpussmall\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# 加载中文的NLP模型，并添加sentencizer组件\n",
    "nlp = spacy.blank(\"zh\")\n",
    "nlp.add_pipe('sentencizer')\n",
    "\n",
    "# 将模型移动到GPU（如果可用）\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# 定义生成文本的函数\n",
    "def generate_article(prompt, max_length=100):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        max_length=max_length,\n",
    "        temperature=0.7,  # 控制生成文本的随机性\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "        repetition_penalty=1.2,\n",
    "        no_repeat_ngram_size=2,  # 避免重复的n-gram\n",
    "        num_return_sequences=1\n",
    "    )\n",
    "    text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return format_article(text)\n",
    "\n",
    "# 定义文本格式化的函数\n",
    "def format_article(text):\n",
    "    # 使用jieba进行分词\n",
    "    words = jieba.lcut(text)\n",
    "    \n",
    "    # 使用spacy进行句子分割和语法分析\n",
    "    doc = nlp(\" \".join(words))\n",
    "    \n",
    "    # 动态换行：每行尽量保证一个完整的短句（5到20个字符之间）\n",
    "    formatted_lines = []\n",
    "    current_line = \"\"\n",
    "    \n",
    "    for sent in doc.sents:\n",
    "        current_line += \"\".join([token.text for token in sent])\n",
    "        if len(current_line) >= 20 or (len(current_line) >= 5 and re.match(r'[。！？]', current_line[-1])):\n",
    "            formatted_lines.append(current_line)\n",
    "            current_line = \"\"\n",
    "    \n",
    "    if current_line:\n",
    "        formatted_lines.append(current_line)\n",
    "    \n",
    "    # 标点符号处理\n",
    "    formatted_text = \"\\n\".join(formatted_lines)\n",
    "    formatted_text = re.sub(r'([^。！？])$', r'\\1。', formatted_text)  # 如果结尾没有标点，添加句号\n",
    "    \n",
    "    return formatted_text\n",
    "\n",
    "# 提示文本\n",
    "prompt = \"写一篇关于人工智能对未来世界影响的简短文章：\"\n",
    "\n",
    "# 生成文章\n",
    "article = generate_article(prompt, max_length=200)\n",
    "\n",
    "# 打印生成的文章\n",
    "print(\"生成的文章：\")\n",
    "print(article)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生成的文章：\n",
      "写 一 篇 关 于 人 工 智 能 对 \n",
      "未 来 世 界 影 响 的 简 短 文 \n",
      "章 ： 人 类 的 未 知 ， 是 由 \n",
      "于 自 然 选 择 的 失 误 。 人 \n",
      "们 在 进 化 过 程 中 ， 不 断 \n",
      "地 寻 找 新 的 生 命 体 ， 而 \n",
      "这 些 新 生 物 ， 正 是 我 们 \n",
      "所 需 要 的 。 《 人 猿 》 作 \n",
      "者 ： 刘 晓 博 出 版 社 ： 北 \n",
      "京 大 学 出 品 人 ： 王 小 波 \n",
      "译 者 简 介 ： 李 开 复 ， 美 \n",
      "国 著 名 科 幻 作 家 、 科 技 \n",
      "评 论 家 ， 曾 任 职 于 美 联 \n",
      "储 主 席 耶 伦 ， 现 为 美 股 \n",
      "市 场 研 究 员 。 他 的 作 品 \n",
      "被 称 为 人 性 的 弱 点 ， 也 \n",
      "被 认 为 是 科 学 与 艺 术 之 \n",
      "间 的 差 异 。 李 先 生 是 一 \n",
      "位 有 着 丰 富 经 验 和 深 厚 \n",
      "理 想 的 科 普 作 曲 家 。 在 \n",
      "他 看 来 ， 人 的 思 维 方 式 \n",
      "是 无 法 改 变 的 ， 因 此 ， \n",
      "他 希 望 通 过 自 己 的 创 造 \n",
      "力 ， 让 更 多 的 人 了 解 人 \n",
      "， 并 且 帮 助 他 们 成 长 。 \n",
      "作 为 一 个 科 研 人 员 ， 李 \n",
      "老 师 的 观 点 非 常 独 到 ， \n",
      "从 他 对 人 脑 的 理 解 ， 到 \n",
      "对 科 教 领 域 的 探 索 ， 都 \n",
      "值 得 我 去 思 考 。 作 文 题 \n",
      "目 ： 《 你 的 梦 想 是 什 么 \n",
      "？ 》 （ 作 ） 作 用 ： 引 导 \n",
      "读 者 从 心 理 学 角 度 分 析 \n",
      "人 与 人 之 交 往 的 本 质 ， \n",
      "以 及 如 何 利 用 人 际 关 系 \n",
      "， 建 立 人 格 。 文 中 提 到 \n",
      "的 你 是 指 人 在 面 临 困 境 \n",
      "时 ， 会 采 取 行 动 的 那 种 \n",
      "人 。 这 种 行 为 可 以 说。\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, BertTokenizer\n",
    "import jieba\n",
    "import re\n",
    "\n",
    "# 加载中文的GPT-2模型和分词器\n",
    "gpt_model_name = \"uer/gpt2-chinese-cluecorpussmall\"\n",
    "model = GPT2LMHeadModel.from_pretrained(gpt_model_name)\n",
    "tokenizer = BertTokenizer.from_pretrained(gpt_model_name)\n",
    "\n",
    "# 将模型移动到GPU（如果可用）\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# 定义生成文本的函数\n",
    "def generate_article(prompt, max_length=200):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        max_length=max_length,\n",
    "        temperature=0.7,\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "        repetition_penalty=1.2,\n",
    "        no_repeat_ngram_size=2,\n",
    "        num_return_sequences=1\n",
    "    )\n",
    "    text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return format_article(text)\n",
    "\n",
    "# 高级文本格式化的函数\n",
    "def format_article(text):\n",
    "    # 使用jieba分词\n",
    "    words = jieba.lcut(text)\n",
    "    formatted_text = \"\"\n",
    "\n",
    "    current_line = \"\"\n",
    "    for word in words:\n",
    "        current_line += word\n",
    "        if len(current_line) >= 20:\n",
    "            formatted_text += current_line + \"\\n\"\n",
    "            current_line = \"\"\n",
    "\n",
    "    if current_line:\n",
    "        formatted_text += current_line\n",
    "\n",
    "    # 处理标点符号\n",
    "    formatted_text = re.sub(r'([^。！？])$', r'\\1。', formatted_text)\n",
    "\n",
    "    return formatted_text\n",
    "\n",
    "# 提示文本\n",
    "prompt = \"写一篇关于人工智能对未来世界影响的简短文章：\"\n",
    "\n",
    "# 生成文章\n",
    "article = generate_article(prompt, max_length=400)\n",
    "\n",
    "# 打印生成的文章\n",
    "print(\"生成的文章：\")\n",
    "print(article)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生成的文章：\n",
      "寫 一 篇 關 於 人 工 智 能 對 未 來 世 界 影 響 的 簡 短 文\n",
      "章 ： 、 、 ， 這 是 我 們 在 中 國 的 一 個 小 小 的 城 市\n",
      "。 我 们 的 大 學 生 活 也 很 豐 富 ， 但 是 有 些 東 西 還\n",
      "不 夠 豐 盛 。 比 如 說 ， 我 想 要 做 一 个 人 造 的 机 器\n",
      "人 ， 可 以 把 我 的 手 臂 放 到 地 上 ， 然 後 用 它 来 控\n",
      "制 我 自 己 的 身 体 。 但 我 覺 得 這 樣 做 太 過 於 繁 琐\n",
      "了 ， 因 為 我 需 要 一 台 機 器 來 幫 助 我 去 完 成 任 務\n",
      "。 所 以 我 希 望 能 够 讓 我 父 母 和 孩 子 都 能 感 受 到\n",
      "人 類 的 快 樂 。 我 觉 得 这 样 的 话 ， 就 像 我 在 看 《\n",
      "星 际 穿 越 》 时 候 说 的 那 样 ， 人 类 的 生 命 已 经 被\n",
      "物 理 学 家 们 证 明 了 。 而 且 ， 他 们 还 提 出 了 一 种\n",
      "新 的 方 法 ， 让 我 可 能 会 去 研 究 人 的 行 为 。 这 种\n",
      "方 式 ， 对 于 我 来 说 非 常 好 。 因 为 我 知 道 ， 在 我\n",
      "看 来 ， 这 是 一 件 非 同 寻 常 的 事 情 。 你 可 知 ， 当\n",
      "你 看 到 一 群 人 在 一 起 玩 耍 的 时 间 ， 你 就 会 发 现\n",
      "， 原 来 人 们 并 没 有 真 正 意 义 上 的 人 。 人 与 人 之\n",
      "间 的 关 系 ， 其 实 是 相 互 依 存 的 。 在 这 里 ， 每 个\n",
      "角 色 都 是 独 立 的 ， 只 是 他 的 位 置 不 同 罢 了 ！ （\n",
      "本 文 由 135 编 辑 器 提 供 技 术 支 持 ） 丨 李 晓 峰\n",
      "编 审 丨 张 志 强 资 料 来 源 丨 网 络。\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, BertTokenizer\n",
    "import jieba\n",
    "import re\n",
    "\n",
    "# 加載中文的GPT-2模型和分詞器\n",
    "gpt_model_name = \"uer/gpt2-chinese-cluecorpussmall\"\n",
    "model = GPT2LMHeadModel.from_pretrained(gpt_model_name)\n",
    "tokenizer = BertTokenizer.from_pretrained(gpt_model_name)\n",
    "\n",
    "# 將模型移動到GPU（如果可用）\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# 定義生成文本的函數\n",
    "def generate_article(prompt, max_length=200):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "    attention_mask = input_ids.ne(tokenizer.pad_token_id)\n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_length=max_length,\n",
    "        temperature=0.7,\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "        repetition_penalty=1.2,\n",
    "        no_repeat_ngram_size=2,\n",
    "        num_return_sequences=1,\n",
    "        pad_token_id=tokenizer.eos_token_id  # 設置pad_token_id\n",
    "    )\n",
    "    text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return format_article(text)\n",
    "\n",
    "# 高級文本格式化的函數\n",
    "def format_article(text):\n",
    "    # 使用jieba分詞\n",
    "    words = jieba.lcut(text)\n",
    "    formatted_text = \"\"\n",
    "\n",
    "    current_line = \"\"\n",
    "    for word in words:\n",
    "        current_line += word\n",
    "        if len(current_line.replace(\" \", \"\")) >= 20:  # 修正字符處理邏輯，確保沒有多餘空格\n",
    "            formatted_text += current_line.strip() + \"\\n\"\n",
    "            current_line = \"\"\n",
    "\n",
    "    if current_line:\n",
    "        formatted_text += current_line.strip()  # 修正最後一行的處理\n",
    "\n",
    "    # 處理標點符號\n",
    "    formatted_text = re.sub(r'([^。！？])$', r'\\1。', formatted_text)\n",
    "\n",
    "    return formatted_text\n",
    "\n",
    "# 提示文本\n",
    "prompt = \"寫一篇關於人工智能對未來世界影響的簡短文章：\"\n",
    "\n",
    "# 生成文章\n",
    "article = generate_article(prompt, max_length=400)\n",
    "\n",
    "# 打印生成的文章\n",
    "print(\"生成的文章：\")\n",
    "print(article)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生成的文章：\n",
      "写 一 篇 关 于 人 工 智 能 对 未 来 世 界 影 响 的 深 入 分\n",
      "析 文 章 ： 、 、 ， 这 是 我 在 问 答 社 区 上 看 到 的 一\n",
      "个 问 题 。 我 想 说 的 是 ， 人 类 的 智 慧 可 以 用 数 学\n",
      "模 型 去 解 释 ， 但 是 如 果 把 它 们 当 做 一 种 技 术 ，\n",
      "那 么 就 会 变 成 一 件 很 难 的 事 情 。 因 为 人 们 不 知\n",
      "道 自 己 有 多 少 智 力 ， 而 且 他 们 也 没 有 办 法 理 解\n",
      "和 记 忆 。 所 以 ， 我 们 只 能 通 过 数 字 化 的 方 式 来\n",
      "进 行 思 考 。 比 如 说 ， 你 可 能 会 发 现 ， 一 些 人 可\n",
      "不 可 怕 ， 可 是 你 却 无 法 预 测 ， 甚 至 连 你 自 身 都\n",
      "无 从 判 断 。 这 样 的 话 ， 就 像 你 的 孩 子 可 怜 巴 巴\n",
      "地 听 着 妈 妈 讲 故 事 ， 然 后 你 就 可 悲 了 。 其 实 ，\n",
      "大 家 都 知 识 太 匮 乏 ， 所 谓 的 智 商 高 低 并 非 真 正\n",
      "意 义 上 的 聪 明 ， 更 多 的 还 是 要 靠 自 觉 性 。 如 何\n",
      "让 自 已 的 脑 子 里 面 的 东 西 变 得 更 加 丰 富 ？ 我 认\n",
      "为 ， 首 先 要 搞 清 楚 什 么 叫 智 障 。 智 者 ， 即 使 是\n",
      "智 人 ， 也 需 要 有 一 定 的 逻 辑 思 维 能 力 。 而 这 种\n",
      "逻 ， 又 是 怎 么 回 事 呢 ？ 就 是 说 ： 智 取 威 虎 山 ，\n",
      "不 仅 仅 是 为 了 赢 得 胜 利 ， 还 要 为 自 我 的 生 存 提\n",
      "供 保 证 。 那 就 好 比 说 一 句 话 ： 我 不 是 傻 瓜 ， 只\n",
      "是 笨 蛋 。 这 句 ， 是 一 位 智 的 哲 学 观 点 。 他 认 同\n",
      "聪 才 的 概 念 ， 认 识 到 了 智 的 本 质 ， 并 且 认 定 了\n",
      "愚 蠢 二 字 。 聪 的 人 往 往 具 备 超 越 常 人 的 天 赋 ，\n",
      "他 的 思 想 是 不 断 地 创 造 新 的 价 值 。 但 智 则 万 物\n",
      "， 智 也 万 象 ， 聪 也 是 人 之 常 情 ， 愚 也 就 不 再 是\n",
      "单 纯 的 意 志 力 了 ， 它 是 由 人 体 内 的 某 些 元 素 构\n",
      "成 的 。 人 与 人 相 处 时 ， 总 是 会 产 生 各 种 各 样 奇\n",
      "怪 的 反 应 ， 比 方 说 你 看 ， 别 人 看 见 我 ， 会 笑 吗\n",
      "？ 别 看 我 长 得 丑 ， 其 他 人 都 看 不 出 来 ！ 等 等 。\n",
      "在 智 智 中 ， 最 重 要 的 就 属 人 了 吧 。 一 般 来 说 人\n",
      "\n",
      "\n",
      "来 ！ 等 等 。 在 智 智 中 ， 最 重 要 的 就 属 人 了 吧 。\n",
      "一 般 来 说 人 都 是 很 有 能 力 的 ， 但 是 他 们 也 不 会\n",
      "太 好 意 思 说 自 己 是 个 聪 明 人 。 所 以 ， 我 们 可 以\n",
      "看 到 ， 智 慧 的 人 往 往 比 较 容 易 被 别 人 利 用 ， 而\n",
      "且 这 种 人 也 是 非 常 善 于 交 际 的 。 那 么 ， 如 何 才\n",
      "能 让 智 商 高 的 智 者 更 加 受 欢 迎 呢 ？ 下 面 就 跟 着\n",
      "小 编 一 起 来 学 习 吧 ！ 1 、 多 读 书 。 2 、 勤 奋 工\n",
      "作 。 3 、 善 待 身 边 的 朋 友 。 4 、 学 会 与 人 相 处\n",
      "。 5 、 做 事 情 要 有 计 划 性 。 6 、 不 要 总 想 着 怎\n",
      "样 去 做 。 7 、 要 懂 得 分 析 问 题 。 8 、 对 自 身 的\n",
      "生 活 状 态 有 清 晰 的 认 识 。 9 、 注 意 饮 食 卫 生 。\n",
      "10 、 保 持 良 好 的 心 理 素 质 。 11 、 养 成 良 性\n",
      "的 社 交 习 惯 。 12 、 培 养 良 善 的 品 格 。 13 、\n",
      "爱 护 环 境 。 14 、 健 康 的 身 体 。 15 、 积 极 乐\n",
      "观 的 精 神 状 况 。 16 、 有 良 知 的 行 为 方 式 。 17\n",
      "、 具 备 良 恶 感 的 能 量 。 18 、 能 够 正 确 地 表 达\n",
      "自 我 。 19 、 勇 敢 地 面 对 困 难 和 挫 折 。 20 、\n",
      "坚 强 地 走 出 阴 霾 。 21 、 乐 于 助 人 ， 善 解 人 意\n",
      "。 22 、 热 爱 生 命 。 23 、 喜 欢 运 动 。 24 、\n",
      "拥 有 健 全 的 体 魄 。 25 、 充 满 活 力 。 26 、 独\n",
      "立 自 主 ， 有 责 任 感 。 27 、 尊 重 他 人 的 选 择 。\n",
      "28 、 自 信 心 强 ， 乐 意 帮 助 别 的 同 伴 。 29 、\n",
      "懂 礼 貌 ， 懂 沟 通 。 30 、 孝 顺 父 母 ， 爱 惜 家 庭\n",
      "。 31 、 谦 虚 谨 慎 ， 不 随 波 逐 流 。 32 、 大 度\n",
      "宽 容 ， 包 容 豁 达 。 33 、 诚 实 守 信 ， 做 人 要 厚\n",
      "道 。 34 、 知 恩 图 报 ， 知 足 常 乐 。 35 、 心 胸\n",
      "开 阔 ， 胸 怀 坦 荡 。 36 、 富 有 仁 义 ， 宽 广 胸 襟\n",
      "。 37 、 忠 诚 老 实 ， 勤 劳 朴 实 。 38 、 德 行 高\n",
      "尚 ， 敬 业 奉 献 。 39 、 无 私 奉 承 ， 服 从 领 导 安\n",
      "排 。 40 、 严 格 遵 守 纪 律 ， 讲 究 原 则 。 41 、\n",
      "吃 苦 耐 劳 ， 团 结 协 作 ， 吃 亏 上 当 。 42 、 优 秀\n",
      "的 孩 子 ， 都 有 一 颗 善 良\n",
      "\n",
      "， 团 结 协 作 ， 吃 亏 上 当 。 42 、 优 秀 的 孩 子 ，\n",
      "都 有 一 颗 善 良 养 成 的 心 。 这 是 我 们 家 长 最 常 说\n",
      "的 话 ， 也 是 最 容 易 被 忽 略 的 一 句 话 。 但 是 ， 在\n",
      "孩 童 时 期 ， 他 们 往 往 会 因 为 缺 乏 安 全 感 而 自 卑\n",
      "， 甚 至 不 敢 面 对 未 来 。 所 以 ， 父 母 要 学 会 给 予\n",
      "孩 提 供 更 多 的 关 爱 和 帮 助 ， 让 孩 儿 懂 得 如 何 去\n",
      "做 人 。 43 、 好 的 教 育 ， 就 是 让 你 的 生 活 充 满\n",
      "乐 趣 。 有 些 父 亲 ， 总 是 把 孩 纸 当 成 小 鸡 仔 ， 把\n",
      "自 己 的 事 情 当 作 玩 具 ， 不 管 怎 么 样 ， 只 要 孩 能\n",
      "够 坚 持 下 去 ， 那 么 ， 孩 就 会 变 得 越 来 越 聪 明 。\n",
      "44 、 孩 之 于 大 人 ， 无 非 是 一 种 责 任 感 ， 一 个\n",
      "人 的 成 功 ， 需 要 付 出 很 多 努 力 才 能 获 得 。 父 爱\n",
      "是 孩 身 体 里 最 重 要 的 部 分 ， 而 且 是 永 远 不 可 替\n",
      "代 的 。 45 、 父 与 子 的 区 别 ， 是 父 权 的 延 续 。\n",
      "在 这 个 世 界 上 ， 没 有 什 么 东 西 比 父 子 间 的 差 异\n",
      "更 值 得 尊 敬 了 。 46 、 我 希 望 每 个 孩 都 能 像 爸\n",
      "爸 一 样 爱 我 ， 并 且 愿 意 为 我 做 点 什 麽 。 47 、\n",
      "有 时 候 ， 我 觉 得 自 由 是 天 性 ， 但 我 却 不 知 道 ，\n",
      "自 从 有 了 孩 ， 便 不 再 是 自 私 的 人 了 ！ 48 、 当\n",
      "你 发 现 自 已 的 行 为 不 合 理 时 ， 请 立 即 停 止 。 49\n",
      "、 如 果 你 想 要 改 变 ， 你 必 须 先 改 掉 自 身 的 坏 习\n",
      "惯 。 50 、 你 应 该 学 着 改 正 自 我 中 心 主 义 ， 然\n",
      "后 再 去 改 进 它 。 51 、 不 要 试 图 改 造 自 个 ， 否\n",
      "则 你 将 失 去 自 信 。 52 、 人 生 的 路 还 很 长 ， 要\n",
      "勇 敢 地 走 下 来 ， 尝 试 新 的 方 式 。 53 、 一 切 都\n",
      "是 为 了 让 自 尊 心 强 大 起 来! 54 、 在 你 快 乐 的\n",
      "时 光 里 ， 别 忘 记 你 曾 经 拥 有 过 的 那 些 美 好 。 55\n",
      "、 生 命 中 ， 有 太 多 事 ， 其 实 都 不 是 真 正 的 幸 福\n",
      "。 56 、 每 一 次 的 失 败 ， 或 许 都 会 带 来 一 些 伤\n",
      "害 ， 这 些 痛 苦 ， 会 让 人 深 思 。 57 、 遇 到 困 难\n",
      "， 首 先 要 找 到 解 决 办 法\n",
      "\n",
      "痛 苦 ， 会 让 人 深 思 。 57 、 遇 到 困 难 ， 首 先 要\n",
      "找 到 解 决 办 法? 我 是 一 个 女 生 ， 在 大 学 里 面 的\n",
      "时 候 ， 有 过 很 多 次 失 败 经 历 ， 但 是 都 没 有 成 功\n",
      "， 因 为 自 己 不 够 优 秀 ， 所 以 才 会 这 样 。 后 来 上\n",
      "了 大 二 ， 开 始 接 触 社 团 ， 也 就 是 说 ， 我 们 班 级\n",
      "里 的 同 学 ， 大 部 分 都 是 从 小 学 到 高 中 毕 业 的 ，\n",
      "而 且 还 有 很 长 一 段 时 间 没 见 面 了 ， 然 后 我 就 去\n",
      "网 吧 打 游 戏 ， 玩 着 玩 著 ， 突 然 发 现 ， 原 来 我 的\n",
      "朋 友 圈 里 ， 好 像 有 一 些 人 ， 他 们 都 已 经 结 婚 生\n",
      "子 了 。 我 想 问 下 ， 这 种 情 况 ， 你 们 怎 么 看 ？ 如\n",
      "果 你 觉 得 你 的 男 朋 很 可 爱 ， 那 么 你 应 该 是 个 很\n",
      "聪 明 的 人 。 如 何 看 待 这 类 人 呢 ？ - - 本 题 来 自\n",
      "问 答 社 区 圆 桌 我 曾 经 和 一 位 女 性 朋 克 青 年 聊 天\n",
      "， 她 告 诉 我 ： 我 认 识 的 女 孩 子 ， 总 是 喜 欢 把 自\n",
      "身 的 缺 点 暴 露 出 来 ， 比 如 说 丑 陋 ， 不 懂 礼 貌 等\n",
      "等 。 她 说 ： 我 觉 的 这 些 缺 陷 ， 只 能 通 过 自 我 修\n",
      "炼 来 改 变 ， 并 不 是 每 个 人 都 适 合 做 一 名 优 雅 的\n",
      "美 丽 的 淑 女 。 所 谓 的 优 质 女 人 其 实 就 包 括 了 自\n",
      "信 ， 自 尊 ， 独 立 ， 勇 敢 ， 坚 强 ， 善 良 ， 乐 观 ，\n",
      "积 极 向 上 等 品 质 。 当 然 ， 优 越 感 也 是 需 要 培 养\n",
      "的 。 话 说 回 来 了 ： 你 知 道 吗 ， 女 神 的 魅 力 ， 除\n",
      "了 外 表 之 外 ， 最 重 要 的 是 内 涵 。 你 看 看 她 的 眼\n",
      "睛 ， 看 起 来 就 像 一 颗 璀 璨 的 星 球 ， 你 可 以 看 到\n",
      "她 若 无 其 事 地 笑 ， 或 者 看 着 她 微 笑 。 她 会 觉 啊\n",
      "， 真 的 很 漂 亮 ！ 她 也 会 对 你 笑 那 你 就 不 用 担 心\n",
      "， 如 此 优 ， 就 算 你 不 知 我 也 不 会 怀 疑 ， 毕 竟 我\n",
      "知 足 常 乐 。 但 我 相 信 你 肯 定 会 有 这 方 面 问 题 ，\n",
      "即 使 你 有 ， 至 少 你 也 有 。 这 个 世 界 上 ， 没 什 么\n",
      "比 你 更 幸 福 的 了 所 有 的 事 情 ， 都 会 给 你 带 来 快\n",
      "乐 ， 让 你 感\n",
      "\n",
      "比 你 更 幸 福 的 了 所 有 的 事 情 ， 都 会 给 你 带 来 快\n",
      "乐 ， 让 你 感 ？ 我 们 总 是 在 不 经 意 间 看 到 一 些 美\n",
      "好 的 东 西 ， 却 忽 略 了 它 们 。 那 么 ， 这 些 事 物 又\n",
      "是 如 何 产 生 的 呢 ？ 或 者 说 ， 它 是 怎 样 产 出 的 ？\n",
      "有 没 有 什 么 特 别 的 故 事 呢 ， 或 许 它 就 是 你 最 幸\n",
      "运 的 时 刻 ？ 谢 邀 ， 我 觉 得 我 很 幸 苦 ， 因 为 我 从\n",
      "小 就 喜 欢 读 书 ， 也 喜 爱 旅 行 ， 但 是 我 并 不 知 道\n",
      "自 己 能 够 做 到 什 麽 程 度 ， 只 是 觉 着 自 由 而 已 。\n",
      "我 想 要 的 是 一 个 安 静 的 环 境 ， 一 份 轻 松 的 心 情\n",
      "。 可 以 去 看 看 电 影 ， 听 听 音 乐 。 也 可 能 去 逛 街\n",
      "， 吃 饭 ， 喝 酒 ， 看 书 。 但 我 真 的 不 喜 歡 那 种 氛\n",
      "围 ， 每 天 都 是 那 样 的 ， 很 压 抑 。 其 实 我 也 不 太\n",
      "喜 ， 可 是 就 像 我 喜 剧 里 面 的 那 句 话 ： 我 不 想 活\n",
      "在 别 人 的 世 界 里 ， 所 以 我 必 须 活 下 去 。 所 谓 的\n",
      "幸 吧 ， 就 算 是 现 在 ， 还 是 会 有 很 多 人 羡 慕 我 ，\n",
      "羡 。 所 幸 的 还 有 我 的 朋 友 ， 他 们 都 很 优 秀 ， 大\n",
      "家 都 非 常 努 力 ， ！ 嗯 ， 其 中 有 一 位 朋 的 父 亲 ，\n",
      "是 个 很 厉 害 的 演 员 ， 当 年 他 和 他 的 女 儿 结 婚 后\n",
      "， 她 的 母 亲 就 把 她 送 进 了 戏 班 学 习 表 演 ， 然 后\n",
      "就 开 始 了 她 一 生 中 最 重 要 最 艰 难 的 岁 月 。 她 在\n",
      "戏 院 里 演 过 一 次 戏 ， 那 场 戏 是 她 第 一 部 戏 的 前\n",
      "半 段 ， 之 后 她 就 再 也 没 见 过 她 。 后 来 她 回 到 家\n",
      "乡 ， 在 一 家 私 企 上 班 ， 工 作 稳 定 ， 收 入 不 错 ，\n",
      "有 房 有 车 ， 生 活 条 件 也 很 好 。 然 而 ， 后 面 几 年\n",
      "， 虽 然 她 成 功 地 找 到 了 一 名 合 适 的 男 朋 ， 结 果\n",
      "却 发 现 ， 原 来 自 身 的 问 题 根 本 解 决 不 了 ， 于 是\n",
      "， 便 开 启 了 另 外 一 番 模 式 。 这 个 模 型 叫 做 幸 存\n",
      "者 偏 差 。 幸 好 ， 幸 亏 ， 没 遇 到 那 个 对 的 人 ， 否\n",
      "则 ， 命 运 就 注 定 了 。 在 这 种 模 拟 的 情 况 下 ， 你\n",
      "会 发 觉 ， 自\n",
      "\n",
      "则 ， 命 运 就 注 定 了 。 在 这 种 模 拟 的 情 况 下 ， 你\n",
      "会 发 觉 ， 自 我 们 是 否 能 够 做 到 ？ 如 果 不 能 ， 那\n",
      "么 我 想 问 ： 为 什 么 ？ 因 为 我 知 道 ， 我 可 以 做 得\n",
      "更 好 ！ 所 以 ， 当 我 看 见 一 个 人 ， 他 的 生 活 和 我\n",
      "的 状 态 有 很 大 关 系 时 ， 便 会 产 生 疑 惑 ， 这 样 的\n",
      "疑 问 究 竟 是 什 麽 呢 ？ 其 实 ， 只 要 你 能 做 出 正 确\n",
      "的 选 择 ， 并 且 愿 意 付 诸 行 动 ， 就 能 解 决 问 题 。\n",
      "但 是 ， 如 何 才 能 让 自 己 变 得 优 秀 呢? 首 先 ， 要\n",
      "明 白 ， 人 生 的 目 标 是 不 断 地 去 完 成 的 ， 而 不 是\n",
      "每 天 都 去 做 。 所 谓 的 目 的 性 ， 即 是 指 你 要 达 到\n",
      "某 些 目 前 的 境 界 ， 或 者 说 你 需 要 做 的 事 情 。 比\n",
      "如 说 ， 在 你 的 人 际 圈 里 ， 有 一 群 人 是 你 最 好 的\n",
      "朋 友 ， 也 有 另 外 一 些 人 你 是 最 棒 的 伙 伴 ， 甚 至\n",
      "还 有 你 自 身 的 特 质 。 然 后 ， 再 来 看 看 你 现 在 的\n",
      "处 境 吧! 你 可 能 会 感 到 困 难 ， 但 你 必 须 要 努 力\n",
      "克 服 它 。 你 应 该 学 习 如 下 的 方 法 : 1. 找 到 你\n",
      "喜 欢 的 工 作 ， 然 後 把 你 所 有 的 精 力 放 在 工 资 上\n",
      "面 。 2. 把 钱 花 在 刀 刃 上 ， 不 要 浪 费 时 间 。 3\n",
      ". 不 管 你 怎 么 努 努 ， 总 有 人 会 给 你 机 会 。 4.\n",
      "你 不 用 担 心 ， 因 此 ， 尽 量 不 去 考 虑 别 人 的 感 受\n",
      "。 5. 如 同 你 在 家 里 一 样 ， 把 自 已 的 烦 恼 全 部\n",
      "抛 掉 。 6. 在 公 司 里 面 ， 保 持 良 好 心 态 ， 积 极\n",
      "向 上 。 7. 对 于 你 来 说 最 重 要 的 是 要 学 会 与 人\n",
      "相 处 ， 学 着 与 他 人 交 往 。 8. 学 一 门 技 术 ， 掌\n",
      "握 一 项 技 能 。 9. 多 参 加 社 团 ， 锻 炼 自 我 ， 提\n",
      "高 自 信 心 。 10. 遇 到 挫 折 ， 及 时 调 整 自 律 。\n",
      "11. 要 善 待 自 尊 ， 多 鼓 励 自 卑 的 孩 子 。 12\n",
      ". 别 让 父 母 失 望 ， 让 他 们 知 足 。 13. 少 吃 零\n",
      "食 ， 少 喝 酒 ， 戒 烟 。 14. 每 周 坚 持 健 身 30\n",
      "分 钟 ， 每 次 20 分 鐘 左 右 。 15. 减 肥 ， 增 肌\n",
      "， 减\n",
      "\n",
      "持 健 身 30 分 钟 ， 每 次 20 分 鐘 左 右 。 15.\n",
      "减 肥 ， 增 肌 ， 减 肉 ， 瘦 腿 ， 有 效 果 吗 ？ 我 是 一\n",
      "个 女 生 ， 从 小 就 胖 ， 体 重 也 不 算 很 大 ， 但 是 现\n",
      "在 已 经 到 了 160 斤 的 水 平 ， 想 要 减 掉 这 些 赘\n",
      "肉 。 我 知 道 自 己 的 问 题 ， 可 能 是 因 为 我 的 饮 食\n",
      "习 惯 和 运 动 方 式 都 比 较 偏 向 于 清 淡 ， 所 以 会 吃\n",
      "很 多 油 腻 的 东 西 ， 而 且 还 会 长 痘 痘 ， 我 该 怎 么\n",
      "办 呢 ？ 谢 邀 ， 你 好 ， 首 先 我 觉 得 你 应 该 去 做 一\n",
      "下 减 脂 ， 然 后 再 去 跑 步 ， 如 果 你 真 的 想 减 少 体\n",
      "内 脂 肪 ， 那 么 你 需 要 做 的 事 情 就 是 ： 1. 控 制\n",
      "饮 酒 2. 保 证 睡 眠 3. 坚 持 锻 炼 4. 多 喝 水 5\n",
      ". 注 意 休 息 6. 避 免 熬 夜 7. 尽 量 减 轻 体 型 8\n",
      ". 不 要 过 度 节 食 9. 少 吃 辛 辣 刺 激 性 食 物 10\n",
      ". 适 当 运 用 运 走 路 11. 慢 跑 12. 跑 完 步 之\n",
      "后 ， 记 住 一 定 要 洗 澡 13. 每 天 早 上 起 来 之 前\n",
      "， 先 把 手 机 放 在 床 边 ， 等 待 第 二 天 的 锻 练 时 间\n",
      "14. 最 后 一 点 ， 不 管 你 是 否 有 运 气 ， 只 要 你\n",
      "坚 信 自 力 量 ， 坚 决 不 能 让 自 行 车 变 成 废 铁 ！ ！\n",
      "（ 图 片 来 源 网 络 ） 乎 君 说 ： 减 重 ， 是 人 类 进 化\n",
      "的 必 然 趋 势 ， 也 是 社 会 发 展 的 基 础 。 我 们 的 生\n",
      "活 中 ， 除 了 工 作 ， 还 有 很 重 要 的 一 部 分 是 学 习\n",
      "， 学 校 里 面 的 课 程 ， 包 括 英 语 ， 数 学 ， 专 业 课\n",
      "， 其 实 都 是 非 常 重 视 学 生 的 学 科 素 养 的 培 养 。\n",
      "所 谓 学 霸 ， 就 像 是 我 国 古 代 的 文 官 ， 他 们 对 学\n",
      "术 研 究 的 态 度 是 严 谨 的 ， 对 于 学 问 的 追 求 是 高\n",
      "深 的 。 而 我 认 识 的 很 少 有 学 者 ， 更 别 提 学 历 了\n",
      "。 学 渣 ， 在 学 院 里 ， 没 有 什 么 学 位 ， 甚 至 连 学\n",
      "士 学 ， 或 者 博 士 ， 都 不 是 。 他 的 目 标 是 ， 通 过\n",
      "学 业 ， 获 取 更 多 的 知 识 ， 并 且 获 得 更 高 的 技 能\n",
      "。 这 样 的 人 ， 才 能 够 在 社 交 场 合 中 脱 颖 而 出 。\n",
      "\n",
      "\n",
      "更 高 的 技 能 。 这 样 的 人 ， 才 能 够 在 社 交 场 合 中\n",
      "脱 颖 而 出 。 ？ 我 是 一 个 大 学 生 ， 现 在 在 读 研 究\n",
      "生 。 我 觉 得 自 己 很 有 资 格 回 答 这 个 问 题 。 首 先\n",
      "， 你 要 明 白 ， 什 么 叫 做 高 手 在 民 间 。 高 考 前 ，\n",
      "我 们 都 知 道 ， 高 三 是 最 难 熬 的 时 候 ， 但 是 ， 如\n",
      "果 你 不 想 放 弃 ， 那 就 去 努 力 吧 ！ 高 二 下 半 年 ，\n",
      "因 为 各 种 原 因 ， 成 绩 没 有 达 到 预 期 ， 所 以 我 选\n",
      "择 了 退 学 。 当 时 ， 家 里 人 也 劝 我 ， 可 以 考 虑 复\n",
      "读 ， 毕 竟 我 还 小 ， 不 懂 事 ， 只 能 靠 自 学 了 。 但\n",
      "我 坚 持 着 ， 从 初 中 开 始 ， 每 天 早 上 起 来 ， 看 着\n",
      "窗 外 的 风 景 ， 感 受 着 阳 光 的 温 暖 ， 然 后 ， 就 会\n",
      "发 现 ， 原 来 自 身 的 能 力 并 不 比 别 人 差 ， 甚 至 比\n",
      "他 们 强 多 少 。 于 是 我 就 开 启 了 自 暴 自 弃 的 模 式\n",
      "。 那 段 时 间 ， 真 的 是 非 常 痛 苦 ， 特 别 是 在 高 中\n",
      "阶 段 ， 。 其 实 ， 这 些 都 是 正 常 的 ， 无 论 是 学 习\n",
      "方 法 ， 还 是 心 态 ， 都 需 要 调 整 。 所 谓 的 高 效 率\n",
      "， 其 本 质 是 对 自 我 的 认 识 和 理 解 ， 而 不 是 单 纯\n",
      "地 把 自 意 义 上 的 成 功 归 结 于 失 败 或 者 挫 折 ， 它\n",
      "们 只 是 表 象 ， 并 没 如 此 。 如 何 让 自 已 的 成 长 变\n",
      "得 更 好 呢 ？ 1. 学 会 独 立 思 考 2. 独 处 时 不 要\n",
      "太 过 分 依 赖 别 的 东 西 3. 不 管 怎 样 ， 独 自 面 对\n",
      "问 ， 总 有 一 天 你 会 遇 见 更 美 丽 的 自 由 4. 找 到\n",
      "适 合 自 个 儿 的 工 作 5. 保 证 充 足 睡 眠 6. 尽 量\n",
      "避 免 与 陌 生 人 接 触 7. 多 参 加 活 动 8. 锻 炼 身\n",
      "体 9. 养 成 良 好 的 生 活 习 惯 10. 健 康 饮 食 11\n",
      ". 注 重 养 生 12. 减 肥 13. 增 加 运 动 14.\n",
      "提 升 自 信 15. 改 善 自 尊 16. 积 极 进 取 17\n",
      ". 培 养 良 性 循 环 18. 创 造 条 件 19. 善 待 自\n",
      "然 20. 勤 奋 21. 爱 惜 羽 毛 22. 珍 惜 自 拍\n",
      "23. 善 用 微 博 24. 关 注 公 众 号 25. 给\n",
      "\n",
      "惜 羽 毛 22. 珍 惜 自 拍 23. 善 用 微 博 24.\n",
      "关 注 公 众 号 25. 给 在 线 生 活 26. 发 布 一 些\n",
      "有 趣 的 照 片 27. 分 享 一 下 你 们 的 故 事 28.\n",
      "我 是 一 个 很 好 奇 的 人 29. 不 要 把 自 己 当 成 一\n",
      "只 小 鸟 30. 别 人 都 说 你 是 个 好 孩 子 31. 你\n",
      "可 以 和 朋 友 一 起 玩 ， 但 请 记 住 ， 不 能 让 别 的 朋\n",
      "伴 看 到 32. 如 果 你 想 要 一 张 自 然 美 丽 的 图 片\n",
      "33. 请 不 断 地 去 学 习 34. 每 天 坚 持 锻 炼 身\n",
      "体 35. 多 喝 水 36. 保 持 良 好 心 态 37. 做\n",
      "一 件 事 情 38. 学 会 放 弃 39. 永 远 不 会 忘 记\n",
      "40. 一 定 要 记 得 41. 爱 上 一 匹 野 马 42.\n",
      "遇 见 一 条 狗 43. 在 路 上 44. 最 后 一 次 相 遇\n",
      "45. 再 也 不 怕 孤 独 46. 没 有 什 么 比 爱 更 重\n",
      "要 了 47. 人 生 就 像 一 场 旅 行 48. 有 时 候 ，\n",
      "你 需 要 的 不 仅 仅 是 勇 气 49. 真 正 的 勇 敢 ， 还\n",
      "有 一 颗 平 常 心 50. 生 命 中 的 每 一 刻 ， 都 值 得\n",
      "被 尊 敬 51. 世 界 上 最 难 过 的 事 ， 莫 过 于 此 52\n",
      ". 总 有 那 么 一 瞬 间 ， 让 你 觉 得 ， 这 辈 子 ， 就 该\n",
      "这 样 。 53. 所 有 的 一 切 ， 终 究 都 是 为 了 你 而\n",
      "存 在 54. 对 待 感 情 ， 其 实 都 应 该 是 平 淡 无 奇\n",
      "55. 喜 欢 一 种 东 西 ， 却 又 不 愿 意 承 认 56.\n",
      "只 要 你 喜 爱 ， 便 不 必 追 求 57. 拥 有 它 ， 即 使\n",
      "失 败 也 会 幸 福 58. 心 里 有 爱 59. 感 谢 你 60\n",
      ". 当 你 的 心 脏 停 止 跳 动 61. 回 忆 往 昔 62.\n",
      "曾 经 的 你 63. 那 些 年 ， 我 们 一 直 在 努 力 64\n",
      ". 现 在 ， 只 是 希 望 你 能 够 找 到 属 于 自 已 的 那 份\n",
      "快 乐 65. 等 待 ， 是 因 为 你 知 道 ， 未 来 的 我 ，\n",
      "将 会 是 怎 样 的 66. 祝 你 早 日 找 回 初 心 67.\n",
      "愿 你 在 人 群 中 安 全 地 走 完 这 段 路 68. 希 冀 ，\n",
      "也 许 你 会 遇 到 一 位 合 适 的 男 人 69. 这 世 上 ，\n",
      "唯 有 真 诚 才 能 打 动 人 70. 相 信 ， 一 旦 遇 上 了\n",
      "， 那 就 是 缘 分 ， 相 守 ， 才 是 真 爱 71. 若 你 不\n",
      "懂 得 珍 视 ， 请\n",
      "\n",
      "， 那 就 是 缘 分 ， 相 守 ， 才 是 真 爱 71. 若 你 不\n",
      "懂 得 珍 视 ， 请 ！ 我 们 都 知 道 ， 人 生 的 路 上 总 有\n",
      "很 多 坎 坷 和 磨 难 。 但 是 ， 在 这 些 坎 中 ， 我 想 说\n",
      "一 句 ： 缘 份 是 最 好 的 安 慰 。 因 为 ， 你 会 发 现 ，\n",
      "有 些 事 情 ， 只 要 你 愿 意 去 做 ， 就 能 够 成 功 ； 而\n",
      "有 时 候 ， 也 许 ， 更 多 的 是 因 果 关 系 。 所 以 ， 当\n",
      "你 遇 到 困 境 、 挫 折 或 者 失 败 的 时 刻 ， 不 妨 停 下\n",
      "来 ， 看 看 自 己 ， 然 后 再 做 出 选 择 。 如 果 你 还 没\n",
      "有 找 到 方 向 ， 可 以 试 着 用 心 经 营 你 的 人 脉 圈 子\n",
      "， 让 他 帮 你 解 决 问 题 。 文 章 转 载 于 网 络 ， 如 侵\n",
      "权 请 联 系 删 除 。 1. 【 微 信 号 】 whwyszx\n",
      "长 按 二 维 码 识 别 关 注 2. 3. 4. 5. 6. 7\n",
      ". 8. 9. 10. 11. 12. 13. 14.\n",
      "15. 16. 17. 18. 19. 20. 21\n",
      ". 22. 23. 24. 26. 27. 34. 32\n",
      ". 33. 36. 37. 38. 39. 41. 40\n",
      ". 42. 46. 44. 35. 51. 52. 54\n",
      ". 66. 56. 53. 61. 62. 64. 67\n",
      ". 65. 68. 72. 74. 76. 75. 86\n",
      ". 77. 79. 81. 82. 83. 84. 78\n",
      ". 88. 85. 89. 87. 91. 73. 80\n",
      ". 90. 92. 93. 94. 96. 97. 99\n",
      ". 95. 98. 69. 70. 100. 101\n",
      ". 102. 103. 108. 110. 111\n",
      ". 112. 104. 109. 105. 107\n",
      ". 106. 113. 114. 115. 116\n",
      ". 117. 119. 127. 129. 128\n",
      ". 130. 131. 132. 126. 134\n",
      ". 137. 135. 136. 138. 141\n",
      ". 142. 145. 146. 149. 151\n",
      ". 152. 153. 154. 150. 162\n",
      ". 161. 160. 159. 164. 163\n",
      ". 166. 165. 158. 157. 167\n",
      ". 168. 169. 170. 172. 173\n",
      ". 171. 174. 175. 176. 177\n",
      ". 178. 179. 187. 188. 185\n",
      ". 186. 191. 192. 184. 190\n",
      ". 189. 193. 198. 199. 194\n",
      ". 195. 197. 201. 202. 203\n",
      ". 204. 206. 211. 210. 222\n",
      ". 221. 214. 205. 208. 209\n",
      ". 212. 207. 215. 213. 226\n",
      ". 220. 223. 232. 231. 228\n",
      ". 227. 218\n",
      "\n",
      "215. 213. 226. 220. 223.\n",
      "232. 231. 228. 227. 218 、\n",
      "中 、 小 学 生 的 教 育 问 题 ， 我 们 都 知 道 ， 在 中 国\n",
      "， 有 一 个 很 重 要 的 现 象 就 是 ， 大 家 对 于 孩 子 的\n",
      "成 长 过 程 中 ， 总 会 遇 到 各 种 各 样 的 困 难 。 比 如\n",
      "说 ， 孩 童 时 期 的 心 理 发 展 和 性 格 特 点 ， 父 母 的\n",
      "态 度 ， 以 及 自 己 的 行 为 方 式 等 等 ， 这 些 都 是 影\n",
      "响 孩 儿 成 年 后 的 一 系 列 问 答 。 那 么 ， 究 竟 什 么\n",
      "样 才 算 是 真 正 意 义 上 的 成 人 化 呢 ？ 其 实 ， 不 管\n",
      "是 哪 种 情 况 下 ， 都 应 该 从 孩 提 时 代 开 始 ， 就 进\n",
      "入 了 成 熟 期 。 而 且 ， 也 许 你 可 能 还 没 有 意 识 到\n",
      "， 当 孩 纸 们 面 临 着 成 功 或 者 失 败 的 时 候 ， 他 们\n",
      "的 内 心 会 产 生 怎 样 一 种 感 受 呢? 其 中 最 常 见 的\n",
      "就 属 于 自 卑 。 因 为 ， 自 信 是 一 切 事 物 的 基 础 ，\n",
      "所 谓 自 尊 ， 即 自 我 认 同 ， 是 指 自 身 的 价 值 观 与\n",
      "世 界 观 的 相 互 作 用 。 自 恋 是 自 然 界 中 存 在 的 东\n",
      "西 ， 它 包 含 着 自 由 、 平 等 、 独 立 、 友 爱 、 自 律\n",
      "、 勇 敢 、 坚 强 、 宽 容 、 谦 逊 、 豁 达 、 乐 观 、 积\n",
      "极 、 健 康 、 向 善 、 诚 实 、 智 慧 、 美 好 、 快 乐 、\n",
      "幸 福 、 喜 悦 、 愉 悦 等 七 种 主 体 。 这 六 种 自 觉 的\n",
      "自 满 ， 表 明 了 自 已 的 优 越 感 ， 并 且 具 有 良 好 的\n",
      "品 质 。 但 是 这 种 优 秀 的 个 性 ， 往 往 被 人 忽 视 ，\n",
      "甚 至 被 社 会 所 抛 弃 。 所 以 ， 无 论 是 在 成 绩 上 ，\n",
      "还 是 学 习 上 都 需 要 自 省 ， 尤 其 是 对 孩 分 数 的 高\n",
      "低 ， 更 需 注 意 。 在 孩 之 初 ， 家 庭 教 养 的 缺 陷 ，\n",
      "使 得 孩 的 性 别 认 知 发 生 了 巨 大 变 化 。 孩 早 期 ，\n",
      "男 女 差 异 较 大 ， 女 孩 更 加 敏 感 脆 弱 ， 而 男 孩 则\n",
      "更 多 地 依 赖 于 外 貌 、 气 质 、 外 形 等 。 随 着 年 龄\n",
      "增 长 ， 性 取 向 的 改 变 ， 对 男 性 的 吸 引 力 减 少 ，\n",
      "从 而 导 致 男 人 对 女 性 产 品 的 偏 爱 降 低 。 男 生 对\n",
      "性 器 官 的 兴 趣 ， 决 定 了 他 的 择\n",
      "\n",
      "性 产 品 的 偏 爱 降 低 。 男 生 对 性 器 官 的 兴 趣 ， 决\n",
      "定 了 他 的 择 么 ？ 我 是 一 个 女 孩 子 ， 从 小 就 喜 欢\n",
      "看 av ， 但 是 不 知 道 为 什 么 ， 总 觉 得 自 己 的 身\n",
      "体 里 有 很 多 东 西 都 是 需 要 保 护 的 ， 比 如 说 阴 茎\n",
      "， 阴 蒂 ， 睾 丸 等 等 ， 而 且 这 些 东 东 也 是 我 们 日\n",
      "常 生 活 中 必 须 要 用 到 的 。 所 以 想 问 下 ， 性 交 时\n",
      "， 男 人 会 不 会 因 为 某 种 原 因 ， 或 者 是 其 它 原 理\n",
      "， 导 致 自 慰 频 率 变 高 ， 甚 至 出 现 勃 起 障 碍 ？ 还\n",
      "是 说 ， 只 是 因 此 而 导 火 索 是 性 欲 ？ （ 我 认 为 性\n",
      "行 为 本 来 就 是 为 了 满 足 自 身 的 欲 望 ） 谢 邀 ， 我\n",
      "觉 着 你 可 能 没 有 那 么 大 的 资 格 回 答 这 个 问 题 。\n",
      "首 先 ， 你 的 性 取 向 是 正 确 的 吗 ？ 如 果 你 是 男 性\n",
      "， 那 你 应 该 是 在 性 方 面 的 选 择 ， 如 何 判 断 你 和\n",
      "你 老 婆 之 间 的 关 系 呢 ？ 你 们 两 个 人 的 感 情 是 否\n",
      "稳 固 ， 是 非 常 重 要 的 ！ 如 今 社 会 上 的 男 女 关 注\n",
      "点 都 在 于 性 爱 ， 所 谓 的 性 ， 就 像 是 爱 一 样 ， 不\n",
      "过 是 把 自 然 界 的 事 物 当 做 一 种 美 好 的 东 再 来 谈\n",
      "谈 性 的 话 题 ， 这 是 个 伪 命 题 啊 。.. 我 不 太 懂\n",
      "， 请 见 谅 。 我 的 观 点 是 ： 性 是 人 类 最 基 本 的 需\n",
      "求 ， 也 许 是 最 简 单 的 生 理 需 性 与 爱 是 相 辅 相 成\n",
      "的 ， 并 不 存 在 绝 对 的 矛 盾 。 性 和 爱 的 区 别 在 哪\n",
      "里 呢 ， 在 我 看 来 ， 它 是 两 件 事 情 ， 一 是 爱 情 二\n",
      "是 婚 姻 。 如 同 你 所 说 的 ： 我 喜 爱 你 ， 却 不 愿 意\n",
      "让 你 受 伤 害 。 这 句 话 ， 其 实 是 对 爱 的 解 释 。 你\n",
      "喜 不 喜 我 也 不 清 楚 ， 反 正 我 。 但 我 真 心 希 望 你\n",
      "能 够 明 白 ， 爱 和 性 是 互 补 的 吧 。 这 就 好 比 你 在\n",
      "一 家 公 司 工 作 ， 每 天 早 晨 醒 来 后 ， 发 现 公 公 公\n",
      "的 手 机 屏 幕 上 显 示 着 一 条 短 信 ： xx ， xx 你\n",
      "好 ， xxx ， xxxx ， 您 好 。 然 后 你 就 开 始\n",
      "了 漫 长 的 等 待 ， 等 到 你\n",
      "\n",
      "xxx ， xxxx ， 您 好 。 然 后 你 就 开 始 了 漫\n",
      "长 的 等 待 ， 等 到 你 ？ 我 是 一 个 很 喜 欢 看 书 的 人\n",
      "， 但 是 我 不 知 道 为 什 么 ， 我 总 觉 得 自 己 在 等 着\n",
      "别 人 来 给 我 讲 故 事 ， 而 且 我 也 没 有 办 法 把 这 些\n",
      "故 弄 玄 虚 的 东 西 讲 出 来 ， 所 以 我 想 问 问 大 家 ，\n",
      "如 果 我 真 的 要 去 做 一 件 事 情 ， 那 么 我 需 要 怎 样\n",
      "才 能 让 自 已 的 生 活 变 得 更 加 丰 富 多 彩 呢 ？ 谢 邀\n",
      "， 先 说 结 论 ： 1. 你 可 以 通 过 阅 读 和 写 作 来 获\n",
      "取 信 息 2. 如 何 提 高 自 身 的 阅 历 3. 当 你 发 现\n",
      "自 我 认 识 的 时 候 ， 你 会 发 觉 自 卑 感 越 来 越 强 烈\n",
      "4. 这 种 情 况 下 ， 最 重 要 的 是 你 要 学 会 放 弃 ，\n",
      "因 为 你 不 再 需 求 别 的 ， 只 要 你 愿 意 ， 就 可 能 成\n",
      "功 5. 我 们 都 知 晓 ， 人 类 社 会 的 进 步 是 由 于 科\n",
      "技 的 发 展 ， 并 且 是 从 无 到 有 ， 从 小 到 大 ， 每 天\n",
      "都 有 新 的 事 物 诞 生 6. 人 们 对 于 自 然 的 敬 畏 之\n",
      "心 ， 远 比 我 人 之 常 情 的 高 7. 在 这 个 世 界 上 ，\n",
      "任 何 一 种 行 为 都 是 不 可 逆 转 的 8. 不 管 你 是 否\n",
      "有 钱 ， 请 记 住 ， 这 是 人 性 的 本 质 9. 一 切 都 将\n",
      "随 着 时 间 的 推 移 10. 爱 情 是 美 好 的 11. 爱\n",
      "是 永 恒 的 12. 有 一 天 ， 爱 会 消 失 13. 生 命\n",
      "中 的 每 一 次 相 遇 都 值 得 铭 记 14. 每 个 人 都 应\n",
      "该 拥 有 属 于 他 们 的 幸 福 15. 世 上 没 什 麽 比 爱\n",
      "更 珍 贵 16. 只 有 爱 与 被 爱 ， 才 是 真 正 的 爱 18\n",
      ". 没 人 能 够 阻 止 你 前 进 19. 谁 都 不 能 保 证 你\n",
      "的 未 来 20. 所 有 的 一 瞬 间 ， 都 会 是 最 美 的 21\n",
      ". 即 使 你 在 某 个 地 方 ， 也 会 有 另 外 一 片 天 24\n",
      ". 无 论 你 走 到 哪 里 ， 它 都 在 24 小 时 25. 请\n",
      "相 信 ， 一 定 有 人 会 陪 伴 你 26. 最 后 ， 祝 大 伙\n",
      "儿 都 能 找 到 自 由 的 归 宿 27. 希 望 大 神 们 能 帮\n",
      "助 我 ， 谢 谢 ！ - - 分 割 线 - 2016 年 10 月\n",
      "17 日 - 2017 年 1 月 23 日 更 新 - 我 的 回\n",
      "答 ： 我\n",
      "\n",
      "16 年 10 月 17 日 - 2017 年 1 月 23 日\n",
      "更 新 - 我 的 回 答 ： 我 大 学 毕 业 后 ， 在 一 家 国 企\n",
      "工 作 了 两 个 多 月 。 现 在 是 公 司 的 副 总 经 理 ， 负\n",
      "责 公 关 部 门 的 工 程 项 目 管 理 和 招 投 标 工 资 。 我\n",
      "们 公 积 金 贷 款 的 事 情 ， 我 也 没 有 办 法 给 他 提 供\n",
      "什 么 方 便 。 但 是 我 觉 得 这 个 问 题 很 好 ， 因 为 我\n",
      "知 道 我 可 以 做 到 。 首 先 ， 你 要 明 白 ， 公 务 员 考\n",
      "试 是 一 个 非 常 严 格 的 考 核 制 度 ， 所 以 你 必 须 要\n",
      "有 相 应 的 准 备 。 其 次 ， 如 果 你 想 要 进 入 体 制 内\n",
      "， 那 就 需 要 对 自 己 的 能 力 有 充 分 的 认 识 。 最 后\n",
      "说 一 下 ， 不 同 于 国 外 的 公 立 医 院 ， 国 内 的 医 疗\n",
      "机 构 的 确 是 比 较 注 重 基 础 性 的 技 术 ， 而 且 还 会\n",
      "根 据 你 的 实 际 情 况 来 选 择 适 合 你 自 身 的 岗 位 。\n",
      "第 三 ， 建 议 你 去 看 看 中 央 财 政 的 全 国 统 一 的 招\n",
      "聘 网 站 ， 里 面 有 很 详 细 的 职 位 信 息 ， 包 括 各 种\n",
      "专 业 的 介 绍 ， 还 有 各 类 的 培 训 课 程 等 等 。 第 四\n",
      "， 关 于 薪 酬 待 遇 ， 这 点 我 不 太 清 楚 ， 但 话 说 回\n",
      "来 ， 这 些 都 是 乎 上 的 东 西 ， 只 是 你 吧 ， 或 者 说\n",
      "你 不 知 ？ ， 请 大 家 不 要 再 纠 结 了 ， 谢 谢 ！ ） -\n",
      "- 本 人 已 经 辞 职 ， 原 因 是 因 。 1. 我 是 在 校 生\n",
      "， 毕 竟 我 还 是 学 生 。 2. 公 共 卫 生 部 的 规 定 ，\n",
      "每 天 早 晨 起 床 后 都 要 洗 漱 ， 然 后 洗 脸 刷 牙 ， 洗\n",
      "手 ， 擦 干 净 手 背 ， 用 毛 巾 擦 拭 手 腕 ， 并 且 每 周\n",
      "至 少 一 次 洗 澡 。 3. 工 商 局 的 通 知 ， 说 明 书 上\n",
      "写 着 每 月 工 龄 满 6 个 月 ， 按 照 规 章 办 理 退 休 手\n",
      "续 。 4. 这 样 的 条 件 ， 是 否 符 合 公 民 的 基 本 素\n",
      "质 呢 ？ 5. 如 何 才 能 让 公 众 知 晓 呢 ， 希 望 大 神\n",
      "们 指 教 。 - 补 充 ： 感 谢 大 伙 的 解 答 ， 虽 然 我 没\n",
      "说 清 具 体 的 时 间 地 点 ， 也 许 是 刚 开 始 工 期 不 够\n",
      "， 导 致 我 错 误 的 判 断 了 。\n",
      "\n",
      "间 地 点 ， 也 许 是 刚 开 始 工 期 不 够 ， 导 致 我 错 误\n",
      "的 判 断 了 。 仔 细 看 菜 单 ， 发 现 价 格 还 算 公 道 ，\n",
      "但 是 味 道 真 的 很 一 般 ， 而 且 服 务 员 态 度 极 差 ，\n",
      "叫 半 天 都 没 人 理 你 。 以 后 再 也 不 会 去 了 ！ 、 、\n",
      "！ 希 望 大 家 注 意 下 ！ ps ： 这 里 的 服 装 质 量 和\n",
      "价 钱 都 比 较 高 ， 如 果 有 机 会 可 以 试 试 ！ 不 过 ，\n",
      "我 觉 得 这 个 店 的 环 境 还 是 不 错 的 ， 就 是 太 吵 了\n",
      "， 不 适 合 情 侣 约 会 。 不 知 道 为 什 么 ， 这 样 的 店\n",
      "， 生 意 好 到 爆 啊 ！ 我 们 两 个 女 孩 子 ， 点 了 一 份\n",
      "套 餐 ， 一 杯 饮 料 ， 吃 完 饭 ， 又 加 了 几 块 钱 ， 结\n",
      "账 时 才 发 觉 ， 原 来 套 系 只 要 30 元 ， 真 是 贵 啊\n",
      "~ ~ ， 以 前 在 其 他 分 店 吃 过 一 次 ， 感 觉 还 行 ，\n",
      "今 天 去 吃 ， 居 然 发 生 了 这 种 事 情 ， 简 直 是 让 我\n",
      "对 这 家 店 失 望 透 顶 ！ 以 上 是 我 的 经 历 ， 希 对 大\n",
      "伙 有 所 帮 助 ！ 另 外 ， 本 人 不 喜 欢 吃 辣 ， 所 以 不\n",
      "能 说 它 不 好 吃 。 但 总 体 来 讲 ， 还 不 如 去 旁 边 的\n",
      "湘 鄂 情 呢 ！ 最 近 一 段 时 间 ， 因 为 同 学 聚 会 ， 特\n",
      "别 想 吃 川 菜 ， 于 是 就 选 择 了 湘 菜 馆 ， 可 是 ， 却\n",
      "发 展 成 了 我 第 二 次 去 的 时 候 ， 那 个 服 了 。 我 记\n",
      "得 当 时 点 的 是 水 煮 鱼 ， 味 精 放 多 了 吧 ？ 我 还 以\n",
      "为 是 酸 梅 汤 呢 ， 后 来 才 知 是 白 开 水 。 这 次 点 菜\n",
      "的 同 志 们 ， 千 万 不 要 点 水 芹 炒 肉 片 ， 虽 然 是 招\n",
      "牌 菜 之 一 ， 口 味 还 可 ， 量 少 ， 价 贵 ， 实 在 是 难\n",
      "以 接 受 。 还 有 一 个 菜 是 干 锅 牛 蛙 ， 做 法 跟 川 办\n",
      "的 差 不 多 ， 只 是 用 的 土 豆 片 和 藕 片 。 味 儿 还 凑\n",
      "合 ， 牛 肉 倒 是 挺 嫩 的 。 总 之 ， 性 价 比 不 高 。 如\n",
      "此 一 来 ， 估 计 以 我 自 己 的 话 ， 应 该 不 回 头 了 ~\n",
      "！ 建 议 大 众 点 评 网 ， 或 者 其 它 网 站 ， 把 这 些 信\n",
      "息 写 出 来 给 大 部 分 人 看 看 ， 大 概 能 找 到 一 些 相\n",
      "关 的 信 号 。 至 于 服 饰 ， 其 实 我\n",
      "\n",
      "人 看 看 ， 大 概 能 找 到 一 些 相 关 的 信 号 。 至 于 服\n",
      "饰 ， 其 实 我 度 还 是 不 错 的 ， 但 是 价 格 也 不 便 宜\n",
      "。 有 时 候 会 去 逛 逛 ， 买 点 小 东 西 。 个 人 觉 得 ，\n",
      "如 果 你 想 要 买 件 衣 服 ， 那 么 这 里 就 很 好 了 。 因\n",
      "为 这 样 可 以 让 你 更 加 放 松 心 情 。 而 且 这 家 店 的\n",
      "环 境 也 很 不 赖 。 所 以 ， 在 这 边 买 衣 物 ， 还 真 是\n",
      "方 便 啊 ！ ~ ~ ！ ~ ！ _ _ 嘻 嘻 。 不 过 ， 这 个 地\n",
      "方 的 服 务 态 度 确 实 不 怎 么 样 。 我 们 买 了 一 件 衬\n",
      "衫 ， 结 账 的 时 侯 ， 他 们 说 没 有 发 票 ， 只 给 了 我\n",
      "一 张 收 据 ， 说 是 没 发 现 ， 然 后 又 打 电 话 来 问 ，\n",
      "才 知 道 ， 原 来 是 他 家 的 员 工 忘 记 拿 发 证 了 ， 郁\n",
      "闷 死 了 ！ 不 知 是 什 么 原 因 ？ ， 我 觉 着 ， 服 装 质\n",
      "量 还 行 吧 ， 款 式 也 挺 多 的 。 但 总 体 感 觉 ， 不 太\n",
      "喜 欢 这 种 风 格 。 希 望 下 次 去 的 朋 友 注 意 哦 ！ 另\n",
      "外 ， 有 一 点 ， 就 是 ， 店 面 的 布 局 和 整 体 的 设 计\n",
      "都 比 较 简 单 ， 没 什 麽 特 色 。 这 点 不 是 很 满 意 。\n",
      "总 之 ， 对 于 这 类 商 品 ， 建 议 大 家 还 算 是 可 靠 的\n",
      "购 买 渠 道 。 毕 竟 ， 它 的 价 位 还 不 低 呢 。 呵 呵 ，\n",
      "希 拉 里 · 克 林 顿 的 支 持 者 们 ， 你 们 的 选 择 是 正\n",
      "确 的 ！ 希 婆 · 罗 素 · 奥 巴 马 的 女 儿 ， 她 的 丈 夫\n",
      "， 也 是 一 名 美 国 公 民 。 她 是 美 联 储 主 席 耶 伦 的\n",
      "妻 子 。 罗 斯 福 的 母 亲 ， 是 著 名 的 经 济 学 家 、 政\n",
      "治 家 。 在 她 生 命 中 ， 曾 经 出 现 过 两 次 重 大 事 故\n",
      "： 第 一 次 是 911 恐 怖 袭 击 ， 当 时 她 被 送 往 医\n",
      "院 ， 医 生 告 诉 她 ， 身 上 有 刀 伤 ， 需 要 手 术 。 第\n",
      "二 次 则 是 在 911 事 件 中 遇 难 。 虽 然 罗 兹 · 卡\n",
      "梅 隆 的 父 亲 是 受 害 者 ， 却 并 非 是 那 种 无 辜 的 人\n",
      "。 他 的 儿 子 ， 从 小 就 被 教 育 要 做 人 ， 要 懂 得 尊\n",
      "重 别 人 的 感 受 。 当 然 ， 罗 伯 特 · 麦 基 的 妈 妈 ，\n",
      "更 是 对 自 己 的 孩 子 负 责 。 作 为 一\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, BertTokenizer\n",
    "import jieba\n",
    "import re\n",
    "\n",
    "# 加载GPT-2模型和分词器\n",
    "gpt_model_name = \"uer/gpt2-chinese-cluecorpussmall\"\n",
    "model = GPT2LMHeadModel.from_pretrained(gpt_model_name)\n",
    "tokenizer = BertTokenizer.from_pretrained(gpt_model_name)\n",
    "\n",
    "# 将模型移动到GPU（如果可用）\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# 定义生成文本的函数\n",
    "def generate_paragraph(prompt, max_length=600):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "    attention_mask = input_ids.ne(tokenizer.pad_token_id)\n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_length=max_length,\n",
    "        temperature=0.7,\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "        repetition_penalty=1.2,\n",
    "        no_repeat_ngram_size=2,\n",
    "        num_return_sequences=1,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return format_paragraph(text)\n",
    "\n",
    "# 定义格式化段落的函数\n",
    "def format_paragraph(text):\n",
    "    words = jieba.lcut(text)\n",
    "    formatted_text = \"\"\n",
    "    current_line = \"\"\n",
    "    for word in words:\n",
    "        current_line += word\n",
    "        if len(current_line.replace(\" \", \"\")) >= 20:\n",
    "            formatted_text += current_line.strip() + \"\\n\"\n",
    "            current_line = \"\"\n",
    "\n",
    "    if current_line:\n",
    "        formatted_text += current_line.strip()\n",
    "\n",
    "    return formatted_text\n",
    "\n",
    "# 生成完整文章的函数\n",
    "def generate_full_article(prompt, target_length=10000, paragraph_length=600):\n",
    "    article = \"\"\n",
    "    while len(article.replace(\" \", \"\")) < target_length:\n",
    "        paragraph = generate_paragraph(prompt, max_length=paragraph_length)\n",
    "        article += paragraph + \"\\n\\n\"\n",
    "        prompt = paragraph[-50:]  # 使用前一段落的最后部分作为下一段落的提示\n",
    "    return article\n",
    "\n",
    "# 提示文本\n",
    "prompt = \"写一篇关于人工智能对未来世界影响的深入分析文章：\"\n",
    "\n",
    "# 生成10,000字的文章\n",
    "article = generate_full_article(prompt, target_length=10000, paragraph_length=600)\n",
    "\n",
    "# 打印生成的文章\n",
    "print(\"生成的文章：\")\n",
    "print(article)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生成的文章：\n",
      "写 一 篇 关 于 人 工 智 能 对 未 来 世 界 影 响 的 深 入 分\n",
      "析 文 章 ： ？ 本 人 是 一 个 技 术 学 院 毕 业 生 ， 现 在\n",
      "在 做 人 机 交 互 相 关 方 面 的 实 验 。 很 早 就 开 始 接\n",
      "触 人 类 与 机 器 之 间 的 沟 通 技 巧 了 ， 比 如 机 械 手\n",
      "和 数 据 传 递 ， 这 些 技 能 我 都 有 过 涉 猎 ， 但 是 并\n",
      "没 有 深 刻 研 究 。 我 们 做 过 一 次 机 会 谈 话 后 ， 我\n",
      "给 出 了 一 份 简 单 的 答 案 ： 未 必 所 有 人 都 喜 欢 你\n",
      "（ 或 者 说 不 会 讨 厌 你 ） ， 而 是 需 要 和 你 讨 论 的\n",
      "事 情 可 以 被 理 解 、 能 够 应 用 到 自 己 身 上 。 因 为\n",
      "在 进 行 实 际 生 活 中 ， 你 无 法 获 得 真 正 的 信 息 ，\n",
      "同 时 也 没 办 法 确 保 你 知 道 任 何 人 和 物 体 的 状 态\n",
      "。 这 种 状 况 下 ， 人 们 就 可 能 把 它 称 作 人 的 思 维\n",
      "过 程 中 所 产 生 的 问 题 。 有 一 句 名 言 叫 做 我 只 会\n",
      "打 字 ， 别 人 却 能 看 见 我 的 样 子 ， 当 然 还 有 另 外\n",
      "一 种 情 况 的 人 ， 他 们 根 本 就 不 懂 人 怎 么 理 性 地\n",
      "处 理 这 件 事 。 举 例 来 说 ， 一 群 年 轻 人 就 像 一 条\n",
      "狗 一 样 ， 从 小 训 练 他 去 学 习 逻 辑 。 他 的 主 要 目\n",
      "标 是 让 他 成 为 一 名 合 格 的 数 学 家 。 最 初 ， 数 字\n",
      "化 计 算 机 可 行 吗 ？ 我 认 为 很 难 ， 甚 至 不 可 想 象\n",
      "。 但 在 某 些 领 域 里 ， 它 能 做 的 更 好 。 在 几 十 万\n",
      "个 智 力 测 试 中 找 到 方 法 论 就 足 够 了 。 然 而 ， 如\n",
      "果 要 做 到 这 点 ， 则 需 花 费 大 量 的 时 间 和 精 力 。\n",
      "比 方 说 google deep learning\n",
      "（ 即 人 脑 神 经 网 络 ） 里 的 一 些 人 在 开 发 一 款 新\n",
      "的 ai 软 件 。 如 今 ， 许 多 人 对 ai 有 着 极 强 的\n",
      "兴 趣 ， 认 识 到 ai 已 经 被 一 般 人 所 忽 略 。 由 此\n",
      "， 几 乎 所 谓 的 科 学 都 将 失 去 意 义 。 不 幸 的 是 ，\n",
      "ai 还 只 是 在 计 划 阶 段 。 许 久 前 ， 谷 歌 推 出 的\n",
      "alphago ， 让 人 惊 叹 的 地 方 在 于 其 精 准\n",
      "度 。 alphago 对 人 才 的 培 养 非 常 严 谨 ，\n",
      "每 天 的 使 用 率 超 过 10 % 。 虽 然 谷 神 也 非 凡 ，\n",
      "在 高\n",
      "\n",
      "常 严 谨 ， 每 天 的 使 用 率 超 过 10 % 。 虽 然 谷 神\n",
      "也 非 凡 ， 在 高 度 上 也 是 同 一 个 水 平 。 但 是 这 里\n",
      "面 有 些 东 西 还 真 的 不 能 保 证 正 确 。 这 个 我 是 认\n",
      "识 的 。 其 实 谷 歌 做 的 最 好 的 就 是 google\n",
      "assistant ， 他 们 都 有 一 套 一 流 的 服\n",
      "务 模 式 。 google 可 以 通 过 服 務 器 提 供 各\n",
      "种 资 源 来 管 理 各 项 业 务 ， 包 括 在 搜 索 引 擎 中 ，\n",
      "google 的 用 户 数 据 库 等 等 。 所 以 要 想 把\n",
      "google 做 得 很 好 ， 那 么 你 必 须 要 有 很 强\n",
      "的 自 主 研 发 能 力 ， 才 能 够 把 工 作 做 到 极 致 。 我\n",
      "在 谷 里 看 了 很 多 文 章 ， 大 家 都 说 到 google\n",
      "， 我 们 自 己 去 找 。 下 面 我 就 来 介 绍 一 下 我 自 身\n",
      "的 经 验 吧 ： 1 、 google 是 一 家 国 外 公 司\n",
      "， 专 注 于 技 术 创 新 和 产 品 开 发 ， 是 全 球 领 先 的\n",
      "技 術 服 裝 集 团 之 一 。 2 、 从 事 的 行 业 分 类 ： 工\n",
      "业 设 计 、 制 造 业 、 金 融 服 装 等 行 当 。 3 、 我 和\n",
      "几 位 朋 友 对 未 来 职 业 规 划 十 分 清 晰 ， 只 要 能 坚\n",
      "持 自 学 考 试 ， 考 上 大 学 后 会 比 较 容 易 。 4 、 能\n",
      "充 分 利 用 时 间 ， 并 且 在 工 科 生 的 领 域 学 习 到 很\n",
      "深 刻 的 知 识 。 5 、 学 校 的 老 师 会 给 予 你 很 重 视\n",
      "的 帮 助 ， 比 如 你 现 在 需 要 哪 些 基 础 课 程 ， 需 不\n",
      "需 跟 班 就 更 加 困 难 了 ， 毕 竟 现 阶 段 的 大 部 分 学\n",
      "生 ， 尤 其 是 女 生 来 说 ， 不 仅 没 有 经 济 方 面 的 优\n",
      "势 ， 而 且 很 难 转 换 为 技 能 ， 就 算 转 学 成 功 了 也\n",
      "不 一 定 就 能 升 任 ceo 或 者 ceo 。 6 、 目 前\n",
      "的 公 众 号 运 营 人 员 ， 多 数 都 是 本 土 人 士 。 因 此\n",
      "， 这 些 人 都 非 常 关 心 企 业 的 发 展 状 况 ， 对 于 企\n",
      "業 发 布 的 新 闻 稿 ， 都 会 进 行 详 细 的 分 析 。 7 、\n",
      "对 企 鹅 账 号 进 一 步 推 广 ， 让 企 客 群 体 在 网 络 上\n",
      "得 到 扩 散 ， 从 而 获 取 信 息 ， 促 进 企 企 商 业 化 。\n",
      "8 、 积 累 自 已 的 营 销 技 巧 与 经 历 ， 提 高 企 营 的\n",
      "效 益 。 9 、 最 近 公 布 在 新 浪 微 博 上 的 内 容\n",
      "\n",
      "历 ， 提 高 企 营 的 效 益 。 9 、 最 近 公 布 在 新 浪 微\n",
      "博 上 的 内 容 在 过 去 一 年 里 ， 我 们 通 过 努 力 可 以\n",
      "收 获 了 非 常 多 的 好 处 。 但 是 ， 很 遗 憾 ， 这 些 好\n",
      "消 息 并 不 能 被 人 所 知 道 。 好 比 说 ， 在 最 初 的 时\n",
      "候 ， 新 闻 都 已 经 报 道 过 ， 如 果 有 人 问 你 要 什 么\n",
      "， 那 你 就 会 告 诉 他 ： 我 要 买 一 杯 咖 啡 。 而 现 在\n",
      "， 因 为 各 种 原 因 ， 他 只 得 到 了 一 个 答 案 ： 因 此\n",
      "， 当 然 是 买 了 咖 式 咖 喱 鸡 腿 饭 。 我 想 ， 咖 哩 鸡\n",
      "排 饭 应 该 算 是 整 个 行 业 里 面 ， 创 造 价 值 最 大 的\n",
      "一 件 事 情 吧 ？ 因 这 次 的 事 故 ， 让 我 看 到 ， 原 来\n",
      "是 因 咖 咖 们 都 在 做 一 些 简 单 粗 暴 的 决 定 ， 为 了\n",
      "提 升 自 己 的 员 工 的 活 跃 度 和 影 响 力 而 做 出 的 妥\n",
      "协 ， 同 样 也 让 人 感 觉 到 它 们 正 在 被 更 多 人 接 受\n",
      "。 每 天 都 有 几 百 万 人 通 电 话 。 这 其 中 ， 有 很 多\n",
      "公 司 都 曾 经 在 尝 试 投 入 巨 资 进 行 创 新 ， 包 括 facebook\n",
      "。 其 实 这 个 世 界 上 没 有 那 么 多 失 败 者 ， 大 部 分\n",
      "人 都 因 失 误 而 丢 掉 了 技 术 ， 甚 至 是 被 淘 汰 。 所\n",
      "以 不 管 怎 样 ， 成 功 人 士 的 故 事 都 是 这 样 的 ： 成\n",
      "本 低 廉 ， 效 率 高 ， 收 益 稳 定 。 那 些 付 出 很 长 时\n",
      "间 却 仍 然 保 持 着 盈 利 的 公 众 号 ， 其 用 户 基 数 还\n",
      "远 未 达 到 预 期 。 当 前 最 热 门 的 文 章 《 为 何 用 五\n",
      "年 时 光 成 立 互 联 网 公 关 公 共 服 务 集 团 》 ， 就 是\n",
      "其 最 具 代 表 性 的 案 例 之 一 ， 也 是 在 这 篇 文 字 中\n",
      "所 述 的 。 如 今 ， 许 多 创 业 者 纷 纷 转 向 互 动 产 品\n",
      "开 发 。 而 对 于 新 兴 互 助 平 台 的 探 索 ， 则 是 对 传\n",
      "统 金 融 领 域 的 颠 覆 性 尝 鲜 。 第 二 类 ： 互 惠 互 利\n",
      "型 。 从 2009 年 开 始 ， 由 于 互 帮 互 赢 模 式 的\n",
      "诞 生 ， 互 相 交 换 信 任 、 互 补 、 共 享 等 方 面 的 价\n",
      "格 优 势 日 渐 凸 显 。 2014 年 互 推 成 为 主 流 。\n",
      "2015 年 ， 国 家 政 策 扶 持 互 金 专 项 整 治 行 动\n",
      "正 式 启 动 。\n",
      "\n",
      "流 。 2015 年 ， 国 家 政 策 扶 持 互 金 专 项 整 治\n",
      "行 动 正 式 启 动 。 一 、 主 要 目 的 1. 规 范 各 类 互\n",
      "联 网 金 融 业 态 ， 优 化 市 场 竞 争 环 境 ， 扭 转 部 分\n",
      "业 务 领 域 存 在 的 劣 币 驱 逐 良 币 现 象 ； 2. 严 厉\n",
      "打 击 非 法 集 资 等 违 法 犯 罪 活 动 ， 保 护 投 资 者 合\n",
      "法 权 益 ， 维 护 金 钱 和 利 益 最 大 化 ， 守 住 不 发 生\n",
      "系 统 性 区 域 性 金 交 易 风 险 可 控 底 线 。 3. 针 对\n",
      "互 相 学 习 借 鉴 、 互 为 补 充 ， 提 高 普 惠 金 服 能 力\n",
      "建 设 效 果 的 互 助 互 信 金 属 平 台 等 创 新 互 贷 模 式\n",
      "； 4. 建 立 监 管 长 效 机 制 ， 加 强 反 欺 诈 技 术 监\n",
      "督 检 查 ； 5. 构 建 完 善 监 测 预 警 体 系 ， 全 面 排\n",
      "除 隐 患 。 二 、 时 间 地 点 （ 一 ） 2016 年 11\n",
      "月 9 日 至 12 日 三 、 重 点 内 容 1 ． 中 央 财 经 大\n",
      "学 互 律 协 会 、 北 京 市 互 促 会 互 益 互 赢 委 员 会 成\n",
      "立 ； 2016 - 2017 年 度 互 济 互 利 共 同 体\n",
      "互 建 工 作 计 划 ； 2017 - 2018 年 间 全 国\n",
      "互 换 互 通 项 目 数 量 突 破 1000 个 ； 四 、 关 于\n",
      "《 互 动 协 议 》 的 主 题 报 告 （ 二 ） 2017 互 博\n",
      "会 组 委 会 协 办 单 位 ： 中 国 人 民 银 行 总 行 中 欧 基\n",
      "金 会 会 址 、 中 华 全 球 贸 易 商 会 展 中 心 ( 上 海 )\n",
      "有 限 公 司 承 办 方 ： 北 大 国 际 金 所 、 香 港 文 汇 报\n",
      "社 协 商 方 式 ： 自 愿 或 委 托 第 三 方 担 任 协 调 员 ，\n",
      "并 与 其 他 会 员 单 独 签 订 协 定 书 。 协 助 协 同 参 与\n",
      "中 英 文 双 语 互 译 及 外 籍 人 士 翻 译 工 程 及 相 关 文\n",
      "件 ， 协 力 解 决 中 美 之 间 的 问 题 。 中 文 互 读 是 指\n",
      "参 加 中 方 对 话 的 中 小 企 业 和 中 介 机 构 可 以 提 供\n",
      "双 边 、 多 边 或 跨 区 间 双 向 的 协 作 与 沟 通 渠 道 ，\n",
      "共 享 自 己 的 资 源 开 拓 市 場 、 拓 展 国 别 市 埸 、 收\n",
      "购 兼 并 、 投 融 资 服 务 等 领 先 的 领 导 力 信 息 ； 中\n",
      "立 协 进 是 中 共 十 八 届 三 中 全 会 提 出 加 快 构 筑 中\n",
      "俄 在 国 防 军 事 领 土 的 战 略 思 想 。 一 般 来 讲 ， 中\n",
      "\n",
      "\n",
      "加 快 构 筑 中 俄 在 国 防 军 事 领 土 的 战 略 思 想 。 一\n",
      "般 来 讲 ， 中 条 约 对 于 俄 罗 斯 在 东 亚 的 作 用 较 为\n",
      "有 限 ， 但 是 对 俄 东 欧 的 影 响 也 很 重 要 ， 这 就 需\n",
      "要 建 立 一 个 以 俄 中 两 方 为 主 导 、 共 同 努 力 的 国\n",
      "际 安 全 合 作 机 制 ， 促 进 地 区 与 平 台 之 间 的 深 度\n",
      "交 流 。 所 谓 共 享 是 指 双 边 关 系 不 断 扩 大 ， 尤 其\n",
      "是 在 当 今 世 界 经 济 发 展 和 国 家 治 理 层 面 上 应 该\n",
      "具 备 的 基 础 设 施 能 够 更 好 地 支 撑 。 如 果 我 们 再\n",
      "从 其 他 角 度 去 看 ， 那 么 一 定 会 感 觉 到 俄 国 在 其\n",
      "它 领 域 的 巨 大 优 势 。 首 先 ， 我 认 为 我 国 正 处 在\n",
      "高 速 发 达 的 近 代 历 史 时 期 。 二 十 几 年 来 ， 俄 方\n",
      "每 次 和 印 度 尼 西 亚 等 邻 国 谈 判 都 非 常 顺 利 。 但\n",
      "在 冷 战 结 束 前 后 ， 美 国 仍 然 保 持 着 对 外 援 助 的\n",
      "态 度 。 例 如 ， 印 尼 将 中 国 视 为 第 四 大 贸 易 伙 伴\n",
      "； 苏 联 在 1991 年 成 功 帮 助 解 决 了 尼 日 尔 问\n",
      "题 ； 日 本 还 在 2009 年 向 波 兰 承 诺 过 提 供 3000\n",
      "亿 卢 布 的 贷 款 。 而 在 今 天 ， 一 些 人 说 俄 已 经 被\n",
      "中 东 国 土 占 据 。 我 想 问 的 是 ， 目 前 俄 乌 两 国 的\n",
      "相 互 依 存 性 如 何 ？ 两 者 最 终 又 会 带 来 什 么 样 的\n",
      "挑 战 ？ 俄 专 家 ： 一 旦 俄 远 离 我 领 空 ， 日 俄 恐 怕\n",
      "只 剩 下 一 条 路 可 走 。 尽 管 我 猜 测 俄 总 统 普 京 可\n",
      "能 在 12 月 份 访 华 ， 并 且 准 备 接 受 媒 体 采 访 时\n",
      "称 ， 俄 政 府 和 民 众 已 通 过 对 话 协 商 ， 以 便 使 得\n",
      "新 的 中 日 关 係 在 未 来 10 年 里 继 续 维 持 增 长 趋\n",
      "势 。 由 此 推 论 ， 在 俄 领 海 内 ， 既 没 有 美 日 菲 三\n",
      "国 ( 包 括 日 韩 ) 的 强 烈 反 对 ， 也 没 必 须 确 认 中\n",
      "方 对 此 的 肯 定 。 因 此 ， 莫 斯 科 和 哈 萨 克 斯 坦 的\n",
      "关 注 度 已 明 显 降 低 。 同 样 ， 伊 朗 和 阿 富 汗 的 支\n",
      "持 度 也 明 确 提 升 ， 可 以 预 见 俄 将 继 步 加 大 对 该\n",
      "国 实 行 军 售 的 力 度 ， 而 且 此 举 将 会 极 大 巩 固 中\n",
      "美 在\n",
      "\n",
      "大 对 该 国 实 行 军 售 的 力 度 ， 而 且 此 举 将 会 极 大\n",
      "巩 固 中 美 在 其 核 武 器 领 域 的 合 作 关 系 。 这 是 否\n",
      "意 味 着 对 于 中 国 来 说 不 再 有 核 战 争 可 能 ？ 如 果\n",
      "真 的 如 网 上 所 言 ， 那 么 它 将 有 助 于 世 界 和 平 与\n",
      "发 展 ， 甚 至 会 让 中 东 地 区 变 得 更 加 安 全 ， 乃 至\n",
      "世 俗 化 ， 成 为 新 一 代 的 超 级 大 国 ！ 中 方 表 示 ：\n",
      "我 们 欢 迎 美 国 参 考 其 他 国 家 的 做 法 ， 并 认 同 其\n",
      "立 场 。 我 方 愿 在 未 来 12 个 月 内 完 成 交 付 任 务\n",
      "。 中 俄 之 间 的 对 话 在 中 断 了 几 年 ， 但 也 没 有 因\n",
      "此 丧 失 主 动 权 ， 随 后 的 两 周 中 就 进 入 中 期 阶 段\n",
      "了 ， 双 方 都 没 把 握 到 机 会 ， 这 次 会 晤 ， 又 在 很\n",
      "短 时 间 里 推 翻 了 以 往 的 四 面 楚 歌 政 策 ， 使 这 些\n",
      "原 本 想 要 继 续 发 挥 作 用 的 协 议 陷 入 了 危 险 。 美\n",
      "日 韩 等 国 也 纷 纷 提 出 不 接 受 中 菲 达 成 的 共 识 ，\n",
      "希 望 将 基 础 设 施 建 设 项 目 逐 步 纳 入 规 划 ， 不 过\n",
      "只 持 有 50 亿 美 元 左 右 的 投 资 额 ， 相 当 于 从 2014\n",
      "年 7 月 开 始 的 6. 5 万 亿 贷 款 ， 需 要 4 - 5 年\n",
      "才 能 收 回 投 入 。 根 据 日 本 官 员 透 露 的 信 息 ， 此\n",
      "外 还 有 另 外 一 个 重 要 问 题 ， 即 中 日 泰 在 南 海 问\n",
      "題 上 的 不 和 解 。 在 越 南 和 日 方 的 态 度 上 ， 分 歧\n",
      "明 显 。 最 近 一 年 来 ， 中 韩 两 国 首 先 就 南 沙 群 岛\n",
      "争 端 向 各 自 方 宣 布 了 决 定 ， 称 中 缅 印 三 国 正 在\n",
      "谈 判 中 。 然 而 ， 在 2015 年 12 月 份 时 ， 南\n",
      "越 和 越 北 双 边 总 理 阮 晋 勇 已 经 达 到 顶 峰 。 阮 朝\n",
      "廷 以 为 ， 应 该 加 强 和 中 越 友 好 的 贸 易 往 来 。 直\n",
      "到 2016 年 8 月 11 日 ， 越 共 总 书 记 阮 光 (\n",
      "francois chevalier ) 访 华\n",
      "期 间 ， 阮 文 绍 的 亲 信 陈 诚 ( cheng kun\n",
      ") 才 被 中 、 越 双 国 民 党 及 其 团 体 扣 留 。 但 这 一\n",
      "切 都 让 美 越 两 大 势 力 陷 于 僵 局 。 日 前 ， 陈 毅 (\n",
      "susan thousand ) 在 北 京 出 席 中\n",
      "央\n",
      "\n",
      "于 僵 局 。 日 前 ， 陈 毅 ( susan thousand\n",
      ") 在 北 京 出 席 中 央 便 利 店 业 务 大 会 时 透 露 ： 在\n",
      "谈 判 过 程 中 ， 我 们 需 要 将 原 来 的 服 务 工 作 做 好\n",
      "， 让 大 家 对 这 个 市 场 有 充 分 了 解 和 认 识 ， 并 且\n",
      "能 够 提 供 更 多 帮 助 。 我 觉 得 这 是 一 个 非 常 重 要\n",
      "的 合 作 伙 伴 关 系 。 从 《 金 融 时 报 》 的 采 访 可 以\n",
      "看 到 ， 于 老 师 表 示 ， 目 前 中 国 经 济 进 入 新 常 态\n",
      "， 加 快 结 构 调 整 、 转 型 升 级 ， 希 望 双 方 在 制 度\n",
      "层 面 达 成 共 识 。 中 方 愿 与 日 本 在 各 领 域 继 续 保\n",
      "持 密 切 沟 通 ， 在 贸 易 上 不 断 深 化 合 同 和 协 议 ，\n",
      "提 高 海 外 投 资 回 报 率 ， 为 双 边 关 键 性 事 件 处 理\n",
      "提 速 创 造 条 件 。 此 次 与 会 嘉 宾 还 就 相 关 话 题 展\n",
      "开 讨 论 。 他 说 ： 虽 然 今 年 1 月 以 来 中 美 两 国 的\n",
      "贸 协 委 员 共 签 署 了 30 份 工 商 业 促 进 协 定 ， 但\n",
      "协 约 内 容 都 没 有 变 化 ， 这 些 协 订 包 括 投 票 权 和\n",
      "股 东 权 益 ， 也 包 含 政 治 和 经 营 管 道 等 方 面 。 而\n",
      "据 悉 ， 如 果 中 止 协 商 ， 双 赢 协 作 或 许 很 难 实 现\n",
      "。 在 昨 天 举 行 的 中 日 韩 ( 安 徽 ) 自 由 贸 试 验 区\n",
      "总 部 暨 第 十 二 届 亚 太 经 合 组 织 峰 会 上 ， 国 务 院\n",
      "总 理 李 克 强 向 记 者 介 绍 了 国 际 经 验 ， 指 出 亚 洲\n",
      "基 础 设 施 投 融 资 体 制 改 革 已 经 取 得 积 极 进 展 ，\n",
      "推 动 形 势 的 发 生 根 本 性 转 变 。 近 期 ， 习 近 平 主\n",
      "席 在 参 观 完 一 带 一 路 建 设 外 交 楼 宇 后 提 出 ， 要\n",
      "加 大 力 度 推 广 使 用 外 资 。 这 意 味 着 中 欧 班 列 将\n",
      "获 得 政 府 支 持 。 在 此 之 前 的 2011 年 ， 中 俄\n",
      "双 向 投 标 引 起 外 界 关 注 。 据 了 知 情 人 士 称 ， 2014\n",
      "年 10 月 中 旬 ， 外 国 商 人 就 中 法 邦 交 正 式 宣 布\n",
      "， 正 在 努 力 打 造 中 华 - 葡 语 国 家 经 贸 合 办 园 区\n",
      "。 随 后 ， 英 国 、 澳 大 利 亚 、 巴 西 、 阿 联 酋 等 地\n",
      "纷 纷 加 入 中 菲 贸 备 竞 赛 。 当 天 下 午 ， 日 媒 曝\n",
      "\n",
      "、 阿 联 酋 等 地 纷 纷 加 入 中 菲 贸 备 竞 赛 。 当 天 下\n",
      "午 ， 日 媒 曝 ， 中 国 加 强 与 菲 律 宾 的 经 济 合 作 伙\n",
      "伴 关 系 已 获 得 成 功 ！ 这 一 消 息 可 能 引 发 热 议 。\n",
      "《 环 球 时 报 》 称 ， 菲 中 两 国 正 在 商 讨 签 署 贸 易\n",
      "协 定 。 根 据 相 关 规 则 ， 双 方 将 在 5 月 30 日 前\n",
      "达 成 谈 判 ， 目 标 是 加 深 中 日 两 军 全 面 战 略 互 惠\n",
      "关 係 ， 以 及 进 一 步 扩 大 双 边 经 贸 往 来 。 另 外 ，\n",
      "中 方 还 要 求 美 方 提 供 关 于 双 赢 和 民 生 援 助 的 建\n",
      "议 ， 同 时 也 希 望 在 6 月 中 旬 之 前 向 菲 方 递 交 回\n",
      "执 。 问 题 五 ： 阿 尔 及 利 亚 、 俄 罗 斯 、 巴 基 斯 坦\n",
      "、 南 非 、 伊 朗 、 叙 利 克 什 米 夫 与 马 里 兰 已 宣 布\n",
      "共 同 开 展 自 由 贸 区 谈 话 。 由 于 近 期 阿 拉 伯 世 界\n",
      "反 政 府 武 装 力 量 对 该 组 织 实 施 轮 番 轰 炸 ， 这 些\n",
      "力 挺 美 国 的 势 力 又 频 繁 出 现 在 各 地 ， 其 中 包 括\n",
      "英 国 、 法 国 和 德 国 。 阿 富 汗 是 中 华 人 民 共 和 国\n",
      "第 二 大 石 油 输 出 国 家 ， 为 争 夺 中 东 地 区 的 主 导\n",
      "权 而 与 南 美 洲 国 土 上 的 各 国 打 了 个 招 呼 。 但 是\n",
      "， 阿 盟 认 为 ， 尽 管 如 此 ， 不 论 是 阿 北 部 还 是 其\n",
      "他 地 方 ， 都 没 有 加 快 与 中 俄 经 过 贸 带 的 友 好 关\n",
      "联 ， 因 为 阿 里 巴 巴 集 团 已 经 在 中 埃 和 平 共 处 六\n",
      "十 多 年 。 我 们 愿 意 通 过 谈 论 对 话 ， 促 使 双 邊 和\n",
      "解 。 我 想 ， 随 着 阿 合 买 办 和 中 央 政 治 局 委 员 会\n",
      "的 指 挥 ， 他 们 正 努 力 改 变 以 往 我 所 做 的 事 情 ，\n",
      "并 且 最 终 达 到 共 识 。 中 欧 与 阿 三 国 际 经 验 分 享\n",
      "： 本 文 由 阿 斯 旺 财 经 独 家 编 辑 发 布 ， 转 载 请 注\n",
      "明 出 处 。 （ 图 片 来 源 网 络 ） 更 多 精 彩 内 容 敬 请\n",
      "关 注 ： http : / / www. aibaiwan\n",
      ". com / club / 105403. html\n",
      "? seller = \" align = center\n",
      "; margin : 0px auto 0 - 100\n",
      "% ; padding : 10px 7px ; line\n",
      "- height : 26px ； color : rgb\n",
      "( 51 ， 51 - 51 ) ; font -\n",
      "\n",
      "ght : 26px ； color : rgb ( 51\n",
      "， 51 - 51 ) ; font - 器 件 ： 3. 5mm\n",
      "音 频 输 入 接 口 ， 可 以 连 接 到 iphone 和 ipad\n",
      "等 设 备 。 这 个 版 本 的 apple watch 支\n",
      "持 nfc 功 能 。 言 归 正 传 ， 我 们 来 看 一 下 ios\n",
      "7 的 界 面 吧 。 不 得 不 说 ， 苹 果 在 今 年 9 月 份 推\n",
      "出 了 第 四 代 applewatch ， 新 的 home\n",
      "键 和 系 统 改 进 了 很 多 。 虽 然 它 没 有 苹 布 斯 那 样\n",
      "出 色 的 操 作 体 验 ， 但 是 它 还 是 拥 有 了 新 型 的 应\n",
      "用 程 序 。 如 果 你 想 要 更 多 的 实 时 图 像 信 息 或 者\n",
      "视 频 资 料 ， 那 么 你 就 需 要 选 择 最 合 适 的 版 块 。\n",
      "你 可 能 会 发 现 ， 这 里 已 经 有 一 些 android\n",
      "手 机 推 送 了 该 版 号 的 文 章 ， 而 且 它 也 同 步 了 几\n",
      "条 基 于 android app 的 消 息 。 所 以 ，\n",
      "对 于 上 述 iphone 设 置 的 android\n",
      "应 该 ， 你 还 需 再 次 考 虑 其 他 问 题 。 在 苹 tv 中\n",
      "， 开 启 了 视 觉 识 别 功 。 而 ios8 正 式 版 的 支\n",
      "援 功 将 被 保 留 至 今 。 当 然 ， 还 有 许 多 方 法 可 供\n",
      "试 用 ！ 比 如 ： 从 点 击 右 上 角 图 标 查 看 桌 面 状 态\n",
      "栏 → 添 加 新 增 界 线 ， 按 照 步 骤 进 行 ， 即 可 进 入\n",
      "到 视 图 搜 索 框 。 另 外 ， 目 前 苹 运 营 商 官 网 内 已\n",
      "无 此 功 。 因 为 ， 此 款 产 品 并 未 支 付 宝 与 微 信 预\n",
      "约 服 务 费 ， 因 此 仅 适 用 于 windows 10\n",
      "。 相 比 之 下 ， android wear 可 提 升\n",
      "用 户 体 积 、 减 少 运 动 数 据 丢 失 。 更 重 要 的 是 ，\n",
      "ios 8 的 安 卓 版 已 在 ios9 之 后 的 首 次 亮\n",
      "相 。 其 中 最 大 的 亮 点 就 是 支 撑 了 google\n",
      "now ， 能 够 连 续 点 触 iphone 或 ipod\n",
      "touch 。 它 们 还 能 通 过 apple pay\n",
      "进 一 步 扩 展 到 电 子 邮 箱 、 网 页 浏 览 器 和 路 由 器\n",
      "等 。 iphone 6 plus 支 架 的 工 艺 将 会\n",
      "提 高 效 率 。 据 悉 ， 除 了 iphone 5c 外 苹\n",
      "a9 搭 载 的 a9 芯 片 也 可 使 用 支 柱 ， 它 能 让 iphone\n",
      "7 plus 在 性 能 方 面 得 到 进 步 。 苹 a8 配 备\n",
      "了 一 块 5 英 寸 1080p 屏 幕 ， 分 辨 率 达 1920x1080\n",
      "像 素 的 fhd 级 别 。 同 时 该 机 还 支 配 了 m8 协\n",
      "处 理 器 ， 以 及 2gb ram +\n",
      "\n",
      "d 级 别 。 同 时 该 机 还 支 配 了 m8 协 处 理 器 ， 以\n",
      "及 2gb ram + 乎 的 ufs2. 0 闪 存 ， 而\n",
      "且 该 手 机 可 能 是 为 了 适 应 苹 果 ios 系 统 而 开\n",
      "发 的 。 如 今 ， htcvive 已 经 升 级 到 了 android\n",
      "4. 1 版 本 ， 并 且 有 望 在 2015 年 11 月 27\n",
      "日 上 市 ， 但 鉴 于 大 家 对 它 还 不 太 熟 悉 ， 不 过 其\n",
      "实 我 们 并 没 有 猜 测 这 款 设 备 会 采 用 什 么 样 的 组\n",
      "合 ， 因 此 我 也 无 法 给 出 任 何 意 见 ， 所 以 我 不 想\n",
      "就 此 告 知 大 伙 。 其 他 相 关 信 息 ： 流 畅 度 提 升 非\n",
      "常 明 显 ， 只 是 机 身 重 量 变 轻 了 ， 整 体 看 起 来 像\n",
      "一 台 小 型 单 反 摄 影 包 ， 价 格 方 面 要 比 专 业 机 便\n",
      "宜 得 多 。 内 部 搭 载 了 htc 第 三 代 sense\n",
      "7 reality 处 置 技 术 ， 拥 有 更 好 的 体 验\n",
      "和 功 耗 控 制 ， 使 得 拍 照 效 果 更 加 清 晰 、 稳 定 。\n",
      "内 存 方 案 方 式 采 取 了 16gb 容 量 ， 运 行 android\n",
      "5. 3 操 作 系 統 。 图 片 上 ， m7 可 以 完 全 自 动\n",
      "升 到 128gb ， 从 图 中 的 数 据 来 看 ， 16gb\n",
      "内 置 的 空 间 很 足 够 用 ， 同 样 也 是 目 前 市 场 上 最\n",
      "大 的 8gb 存 储 卡 ， 也 算 是 让 人 满 意 的 了 。 另\n",
      "外 还 有 一 个 重 要 的 问 题 就 是 ， 它 的 屏 幕 分 辨 率\n",
      "是 1080p ， 屏 占 比 达 到 87 % ， 相 当 于 1080p\n",
      "的 两 倍 ， 与 iphone 6 plus 相 似 。 除\n",
      "此 之 外 ， 其 余 的 都 是 基 于 android5.\n",
      "2 的 处 境 ， 这 种 感 觉 很 棒 。 不 妨 去 看 看 魅 族 pro6s\n",
      "， 或 者 说 用 友 网 吧 的 小 编 ， 他 们 的 机 子 都 支 持\n",
      "1080p 视 频 播 放 ， 至 少 我 是 这 样 认 为 的 ！\n",
      "手 环 相 机 类 型 ： 单 电 类 设 计 语 言 ： emotional\n",
      "/ emmc 类 架 构 ： java / androidrom\n",
      "类 别 ： 电 池 类 容 器 类 号 ： tp - link 手 势\n",
      "识 别 技 巧 ： 双 向 控 控 （ 简 称 idd ） 功 能 ： 通\n",
      "过 触 摸 屏 对 手 指 进 行 按 压 ， 即 使 按 住 手 上 的 按\n",
      "键 ， 手 表 依 然 保 持 正 确 姿 态 ， 没 错 ， 就 在 那 里\n",
      "。 它 不 仅 能 识 字 ， 连 拍 ， 还 能 打 电 话 。 你 可 曾\n",
      "想 过 ， 每 次 用 手 掌\n",
      "\n",
      "仅 能 识 字 ， 连 拍 ， 还 能 打 电 话 。 你 可 曾 想 过 ，\n",
      "每 次 用 手 掌 扣 住 一 部 分 ， 对 方 都 能 看 到 ！ （ 内\n",
      "附 ppt ） 这 些 照 片 的 背 后 ， 是 你 拍 摄 视 频 时\n",
      "的 技 术 动 作 ， 而 不 是 一 个 人 在 拍 ！ 这 位 爸 爸 为\n",
      "了 让 孩 子 在 大 屏 幕 上 轻 松 看 得 清 楚 ， 特 意 找 来\n",
      "了 一 台 光 学 镜 头 ， 通 过 对 比 ， 将 他 拍 成 了 如 此\n",
      "模 糊 的 画 面 。 现 场 有 专 家 表 示 ， 只 要 掌 握 了 基\n",
      "本 的 摄 影 常 识 ， 也 就 能 够 发 挥 很 好 的 效 果 了 。\n",
      "那 么 ， 手 机 中 的 这 个 功 能 ， 我 们 能 做 吗 ？ 对 于\n",
      "用 户 来 说 ， 无 非 是 两 个 问 题 ： 1 、 拍 出 来 的 东\n",
      "西 是 否 真 实 。 2 、 怎 样 才 能 让 他 们 知 道 自 己 拍\n",
      "的 究 竟 是 什 么 样 子 呢 ？ 1. 手 持 型 iphone\n",
      "6 plus 的 手 托 式 电 池 续 航 时 间 长 达 三 天 以\n",
      "上 ， 续 驶 里 程 可 达 100 公 里 ； 2. 带 有 gps\n",
      "导 航 系 统 的 iphone 7 plus 则 能 充 满\n",
      "5 分 钟 ； 3. 搭 载 wifi 功 耗 降 低 30 % ；\n",
      "4. 支 持 自 助 洗 衣 服 等 基 础 设 施 ， 如 果 使 用 智\n",
      "能 手 环 的 话 ， 最 高 能 节 省 120 元 左 右 的 洗 涤\n",
      "费 用 。 这 是 目 前 为 止 国 产 手 感 最 棒 的 一 款 iphone\n",
      "手 拿 式 智 慧 型 手 表 ， 拥 有 十 倍 于 传 统 智 商 的 拍\n",
      "照 能 力 。 另 外 ， 该 款 手 手 套 采 用 了 18k 镀 金\n",
      "材 质 ， 佩 戴 起 来 更 加 舒 适 柔 软 ， 同 时 还 具 备 防\n",
      "水 性 能 和 更 强 韧 度 。 小 编 推 荐 关 注 小 伙 伴 们 在\n",
      "购 买 iphone 之 前 请 先 试 听 下 这 款 新 机 的\n",
      "测 评 ， 或 者 选 择 其 它 品 牌 的 智 趣 手 袋 。 内 容 综\n",
      "合 整 理 ， 转 载 请 保 留 版 权 信 息 。 如 需 了 解 详 情\n",
      "请 联 系 小 智 君 微 信 号 ： qiaoxiaoyang\n",
      "， 获 取 更 多 优 惠 资 讯 。 更 有 多 种 好 礼 送 不 停 ，\n",
      "欢 迎 您 拨 打 热 线 电 询 ： 400 - 809 - 1111\n",
      "转 889880 。 【 关 键 词 】 | 光 圈 曝 光 、 全\n",
      "景 声 、 夜 景 照 、 hdr 、 无 损 音 乐 、 蓝 牙 音 响\n",
      "、 遥 控 器 、 音 箱 【 点 击 查 看 原 文 】 | 摄\n",
      "\n",
      "损 音 乐 、 蓝 牙 音 响 、 遥 控 器 、 音 箱 【 点 击 查 看\n",
      "原 文 】 | 摄 前 言 ： 在 大 多 数 人 的 生 活 中 ， 我 们\n",
      "总 是 用 耳 机 听 歌 、 收 听 mp3 。 但 对 于 普 通 消\n",
      "费 者 而 言 ， 一 个 好 的 产 品 所 带 来 的 声 音 和 享 受\n",
      "却 远 不 止 这 些 。 耳 塞 式 电 脑 、 迷 你 无 线 网 络 、\n",
      "触 摸 屏 等 等 都 可 以 让 音 质 达 到 最 佳 状 态 ， 还 能\n",
      "为 音 频 播 放 提 供 更 加 稳 定 和 有 效 的 保 障 。 而 很\n",
      "多 人 认 为 ， 这 样 的 设 备 会 让 耳 朵 得 不 到 充 分 休\n",
      "息 ， 因 此 在 使 用 过 程 中 容 易 发 生 低 级 错 误 。 其\n",
      "实 ， 就 算 是 真 正 的 耳 夹 式 收 音 机 ， 也 只 有 少 部\n",
      "分 功 能 被 完 全 开 启 ， 比 如 蓝 光 播 报 ， 或 者 是 录\n",
      "音 笔 等 ， 但 其 他 方 面 仍 然 没 法 满 足 人 们 日 常 使\n",
      "命 ， 尤 其 是 老 年 人 。 当 耳 罩 式 变 成 了 现 代 时 尚\n",
      "的 流 行 趋 势 之 后 ， 智 能 化 的 蓝 宝 石 耳 环 便 开 始\n",
      "越 来 越 多 地 出 现 在 市 场 上 。 相 信 大 家 对 智 慧 型\n",
      "蓝 色 耳 挂 耳 感 兴 趣 ， 那 么 今 天 小 编 给 大 伙 推 荐\n",
      "几 款 简 单 又 经 济 实 惠 的 手 机 。 首 先 ， 飞 利 浦 （\n",
      "philips ） philips 飞 科 fh620w\n",
      "高 端 蓝 猫 ii / air 双 立 体 声 耳 麦 。 飞 翔 蓝\n",
      "鸟 的 外 形 简 洁 优 雅 ， 采 用 黑 色 的 配 色 ， 并 且 富\n",
      "有 明 亮 的 金 属 质 感 ， 搭 载 2. 0ghz 四 核 处\n",
      "理 器 ， 支 持 802. 11ac 协 议 传 输 速 率 。\n",
      "搭 配 usb type - c 接 口 ， 拥 有 16gb\n",
      "tf 卡 扩 展 存 储 空 间 ， 同 时 具 有 wifi 功 耗\n",
      "及 蓝 魔 芯 片 。 此 外 ， fs610 的 音 源 插 孔 位\n",
      "置 也 非 常 巧 妙 ， 在 接 听 蓝 盒 子 的 时 候 ， 它 能 够\n",
      "自 动 进 入 蓝 碟 播 送 系 统 ， 让 视 频 输 出 更 快 捷 。\n",
      "另 外 飞 鹰 k111c - m7 ， 配 合 双 扬 声 器 和\n",
      "低 音 炮 ， 能 轻 松 应 对 不 同 的 环 境 ， 音 量 可 调 节\n",
      "至 150 瓦 ， 实 现 超 强 静 音 。 据 介 绍 ， 该 耳 套\n",
      "由 飞 亚 达 集 团 和 深 圳 国 际 智 联 创 意 产 业 园 共 同\n",
      "打 造 ， 旨 在 将 创 新 性 的 互 联 网\n",
      "\n",
      "圳 国 际 智 联 创 意 产 业 园 共 同 打 造 ， 旨 在 将 创 新\n",
      "性 的 互 联 网 用 、 智 能 化 生 活 方 式 引 进 入 中 小 企\n",
      "业 。 经 过 一 年 多 的 发 展 ， 该 园 区 已 成 为 众 多 知\n",
      "名 的 科 技 创 客 空 间 ， 并 积 极 探 索 以 技 术 和 商 务\n",
      "实 现 工 作 与 生 产 的 跨 界 融 合 。 目 前 ， 已 有 5 家\n",
      "创 业 型 孵 化 器 入 驻 ， 包 括 腾 讯 科 学 技 巧 服 务 平\n",
      "台 、 广 州 天 地 、 华 南 理 工 大 学 东 华 学 院 等 7 家\n",
      "孵 孵 平 臺 ， 其 中 2 家 拟 落 户 新 莞 人 才 培 养 基 地\n",
      "。 该 项 目 由 原 国 内 首 个 创 造 性 创 投 工 场 国 家 高\n",
      "新 技 能 人 数 量 工 厂 等 10 个 项 项 组 成 ， 总 面 积\n",
      "达 15. 4 万 ㎡ ， 由 北 京 天 谷 科 创 孵 投 资 集 团\n",
      "、 南 京 东 湖 众 筹 服 （ 北 海 ） 股 份 有 限 公 司 、 深\n",
      "圳 市 新 华 三 信 息 咨 询 有 权 有 偿 使 用 中 心 等 5 个\n",
      "单 位 建 立 合 作 ， 共 享 创 想 空 气 、 开 放 创 富 空 境\n",
      "。 据 了 解 ， 此 次 与 新 京 报 社 携 手 ， 为 北 航 动 漫\n",
      "研 究 所 、 光 明 日 报 传 媒 及 广 电 系 统 企 事 业 单 元\n",
      "及 全 球 顶 级 知 识 分 子 提 供 创 编 和 翻 译 的 专 业 视\n",
      "频 课 程 。 创 作 性 孵 园 是 由 新 浪 科 尔 沁 文 化 传 播\n",
      "有 着 多 年 历 史 的 新 锐 媒 体 人 王 俊 杰 所 操 刀 ， 负\n",
      "责 创 办 的 一 项 融 媒 领 域 的 重 要 组 织 架 构 创 建 。\n",
      "作 为 新 闻 出 版 行 政 部 门 支 持 的 创 始 机 构 ， 新 文\n",
      "艺 创 刊 于 2014 年 10 月 1 日 ， 致 力 于 让 每\n",
      "一 位 读 者 都 能 够 感 受 到 新 鲜 和 刺 激 的 视 觉 盛 宴\n",
      "， 也 是 新 一 代 观 众 走 向 文 学 、 历 久 弥 新 的 平 衡\n",
      "点 。 新 书 《 创 变 》 将 借 助 新 媒 介 与 影 像 传 递 信\n",
      "念 与 精 神 风 貌 ， 结 合 新 兴 媒 源 为 观 者 呈 现 更 加\n",
      "丰 富 的 内 容 ， 满 足 不 同 时 期 读 主 体 对 新 颖 、 独\n",
      "特 的 思 考 方 法 和 表 达 方 案 的 需 求 ， 打 破 传 统 媒\n",
      "土 、 媒 材 与 文 字 之 隔 阂 ， 赋 予 新 诗 歌 的 形 象 ，\n",
      "在 多 元 文 本 中 运 用 新 词 汇 ， 通 过 语 言 、 图 画\n",
      "\n",
      "诗 歌 的 形 象 ， 在 多 元 文 本 中 运 用 新 词 汇 ， 通 过\n",
      "语 言 、 图 画 绘 等 方 式 表 达 出 来 ， 是 为 什 么 ？ 比\n",
      "如 ： 我 想 你 了 。 嗯 好 好 笑 。 （ 这 句 话 很 有 意 思\n",
      "） 你 给 我 听 一 个 喜 欢 或 者 爱 情 的 名 字 。 （ 当 然\n",
      "也 可 以 是 对 人 物 命 运 的 理 解 ， 但 可 能 更 贴 近 现\n",
      "实 ， 更 能 引 起 共 鸣 ） - - 啊 ！ 其 实 我 觉 得 应 该\n",
      "还 有 其 他 例 子 。 比 较 适 合 用 现 代 汉 语 词 典 里 面\n",
      "的 词 组 和 句 型 来 作 为 分 类 。 因 为 ： 1. 语 法 中\n",
      "可 用 到 的 不 只 是 语 义 上 的 变 化 ， 而 是 全 部 的 结\n",
      "构 体 系 。 2. 能 够 使 用 单 纯 的 语 境 去 描 述 事 物\n",
      "， 就 像 用 数 学 的 公 式 解 释 科 学 问 题 一 样 。 3.\n",
      "它 们 是 不 同 的 ， 这 些 都 需 要 你 去 进 行 深 入 思 考\n",
      "。 4. 通 俗 易 懂 ， 无 论 是 诗 性 还 是 词 性 。 5.\n",
      "你 会 发 现 其 它 许 多 形 式 都 可 常 态 化 地 生 存 下 去\n",
      "。 6. 诗 体 结 果 的 完 美 是 由 于 它 的 诗 意 性 和 词\n",
      "义 性 带 来 的 。 7. 这 种 诗 有 时 候 是 一 种 自 然 的\n",
      "风 格 。 8. 其 次 ， 还 可 从 诗 的 特 征 去 找 到 诗 人\n",
      "的 写 作 手 段 ， 或 是 某 种 语 感 的 延 续 。 9. 每 首\n",
      "诗 都 有 自 己 独 特 的 主 观 性 ， 那 么 是 什 总 结 出 一\n",
      "些 有 代 表 性 的 精 彩 的 故 事 呢 ？ 相 关 问 答 ： 我 看\n",
      "的 第 一 篇 诗 （ 可 是 我 没 有 读 过 ） 是 在 一 家 书 店\n",
      "里 ， 翻 译 成 英 文 的 一 位 朋 友 写 的 ： he has\n",
      "an honor of the nights from\n",
      "a which is it once they were\n",
      "told you and always without\n",
      "one of those who live in my\n",
      "life. i'm not going for that\n",
      "it wasn't better than he\n",
      "felt at this book. when he\n",
      "had ready by his wife and\n",
      "he comes down by he among\n",
      "her body. he she is no longer\n",
      "as good time to do with me\n",
      ". 他 说 ， 我 希 望 他 把 书 放 在 我 身 边 ， 让 我 知 道\n",
      "， 他 在 哪 里 。 so there are also\n",
      "， someone who happened about\n",
      "what is your eyes ， but if\n",
      "you can see you them\n",
      "\n",
      "ut what is your eyes ， but\n",
      "if you can see you them 丹 尼\n",
      "斯 · 罗 宾 逊 （ ； ） 是 一 位 美 国 演 员 、 作 家 和 剧\n",
      "本 家 。 他 的 作 品 以 及 其 他 作 者 还 有 电 视 剧 《 》\n",
      "等 。 在 他 出 生 于 德 克 萨 斯 州 的 阿 拉 巴 马 州 （ atlas\n",
      "） 。 父 亲 是 著 名 的 演 讲 家 、 导 演 和 影 评 人 。 母\n",
      "亲 则 为 歌 手 和 演 技 派 知 名 人 士 。 在 家 乡 开 了 两\n",
      "年 工 厂 。 毕 业 后 就 读 于 加 利 福 尼 亚 大 学 柏 克 莱\n",
      "分 校 （ california institute\n",
      "of technology ） ， 之 后 前 往 麻 省\n",
      "理 工 学 院 （ mit ） 进 修 。 之 所 以 选 择 这 所 私\n",
      "立 高 中 是 因 为 她 对 自 己 的 文 化 非 常 感 兴 趣 。 我\n",
      "认 识 很 多 在 那 里 成 长 起 来 的 朋 友 ， 并 且 都 觉 得\n",
      "不 能 够 被 外 界 看 到 ， 但 我 真 正 感 受 到 的 是 ， 我\n",
      "会 用 心 去 做 我 想 做 的 事 情 ， 而 不 是 像 别 人 那 样\n",
      "。 最 初 我 喜 欢 上 音 乐 ， 也 许 他 们 只 是 玩 一 些 小\n",
      "游 戏 。 我 有 好 几 个 朋 伴 。 可 是 他 最 终 没 有 从 音\n",
      "响 界 走 出 来 。 当 他 遇 见 一 群 可 爱 的 女 孩 子 时 ，\n",
      "他 把 我 带 到 了 另 一 条 路 。 同 时 他 也 在 寻 找 一 种\n",
      "新 的 方 式 。 从 这 里 经 过 时 间 的 洗 礼 后 ， 音 符 变\n",
      "得 更 加 丰 富 ， 变 成 了 各 类 语 言 ， 最 后 他 变 回 了\n",
      "英 语 、 数 字 和 诗 歌 。 但 他 发 现 这 些 词 汇 和 他 本\n",
      "身 的 口 头 禅 相 差 甚 远 。 这 让 他 意 识 到 ： 我 应 该\n",
      "多 关 注 自 然 界 的 形 态 ， 比 如 水 、 火 、 土 壤 、 植\n",
      "物 。 由 此 ， 在 我 的 记 忆 中 ， 无 论 什 么 东 西 在 哪\n",
      "儿 都 是 美 丽 的 。 而 我 不 再 需 要 太 多 东 东 。 直 到\n",
      "我 成 为 了 一 名 音 频 编 辑 。 现 在 ， 那 些 听 过 我 声\n",
      "音 的 人 给 我 提 供 了 他 想 说 的 话 。 不 管 是 什 麼 歌\n",
      "曲 ， 它 们 或 者 是 我 要 唱 的 那 首 歌 ， 都 将 令 我 流\n",
      "泪 。 一 次 ， 丹 麦 的 一 家 医 疗 诊 所 打 来 电 话 ， 说\n",
      "要 求 我 先 把 电 脑 关 掉 ， 然 后 把 显 示 器 关 了 。 对\n",
      "方 回 答 道 ： 你 能 保 证 你 在 网 络 上 获 取 信 息 吗 ？\n",
      "丹 · 布\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, BertTokenizer, pipeline\n",
    "import jieba\n",
    "import re\n",
    "\n",
    "# 加载GPT-2模型和分词器\n",
    "gpt_model_name = \"uer/gpt2-chinese-cluecorpussmall\"\n",
    "model = GPT2LMHeadModel.from_pretrained(gpt_model_name)\n",
    "tokenizer = BertTokenizer.from_pretrained(gpt_model_name)\n",
    "\n",
    "# 使用pipeline加载生成管道，指定设备为GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "text_generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device=0 if torch.cuda.is_available() else -1)\n",
    "\n",
    "# 定义生成段落的函数，支持多次生成候选段落\n",
    "def generate_paragraph(prompt, max_length=600, num_return_sequences=5):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "    attention_mask = input_ids.ne(tokenizer.pad_token_id)\n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_length=max_length,\n",
    "        temperature=0.7,\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "        repetition_penalty=1.2,\n",
    "        no_repeat_ngram_size=2,\n",
    "        num_return_sequences=num_return_sequences,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    candidates = [tokenizer.decode(o, skip_special_tokens=True) for o in output]\n",
    "    # 使用BERTScore或其他质量评估方法选择最佳候选段落\n",
    "    best_candidate = max(candidates, key=lambda x: len(x))  # 简单选择最长的段落\n",
    "    return format_paragraph(best_candidate)\n",
    "\n",
    "# 定义格式化段落的函数\n",
    "def format_paragraph(text):\n",
    "    words = jieba.lcut(text)\n",
    "    formatted_text = \"\"\n",
    "    current_line = \"\"\n",
    "    for word in words:\n",
    "        current_line += word\n",
    "        if len(current_line.replace(\" \", \"\")) >= 20:\n",
    "            formatted_text += current_line.strip() + \"\\n\"\n",
    "            current_line = \"\"\n",
    "\n",
    "    if current_line:\n",
    "        formatted_text += current_line.strip()\n",
    "\n",
    "    return formatted_text\n",
    "\n",
    "# 生成完整文章的函数\n",
    "def generate_full_article(prompt, target_length=10000, paragraph_length=600):\n",
    "    article = \"\"\n",
    "    while len(article.replace(\" \", \"\")) < target_length:\n",
    "        paragraph = generate_paragraph(prompt, max_length=paragraph_length)\n",
    "        article += paragraph + \"\\n\\n\"\n",
    "        prompt = paragraph[-50:]  # 使用前一段落的最后部分作为下一段落的提示\n",
    "    return article\n",
    "\n",
    "# 提示文本\n",
    "prompt = \"写一篇关于人工智能对未来世界影响的深入分析文章：\"\n",
    "\n",
    "# 生成10,000字的文章\n",
    "article = generate_full_article(prompt, target_length=10000, paragraph_length=600)\n",
    "\n",
    "# 打印生成的文章\n",
    "print(\"生成的文章：\")\n",
    "print(article)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生成的文章已保存到 generated_article_traditional.txt 文件中\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, GPT2LMHeadModel\n",
    "import jieba\n",
    "import opencc\n",
    "\n",
    "# 使用Hugging Face提供的标准中文GPT-2模型\n",
    "model_name = \"uer/gpt2-chinese-cluecorpussmall\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = BertTokenizer.from_pretrained(\"uer/gpt2-chinese-cluecorpussmall\")\n",
    "\n",
    "# 将模型移动到GPU（如果可用）\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# 创建繁简转换器\n",
    "cc = opencc.OpenCC('s2t')  # s2t 是 Simplified to Traditional 的简写\n",
    "\n",
    "# 定义生成段落的函数\n",
    "def generate_paragraph(prompt, max_length=600):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "    attention_mask = input_ids.ne(tokenizer.pad_token_id)  # 设置 attention_mask\n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_length=max_length,\n",
    "        temperature=0.7,\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "        repetition_penalty=1.2,\n",
    "        no_repeat_ngram_size=2,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    traditional_text = cc.convert(text)  # 转换为繁体中文\n",
    "    return format_paragraph(traditional_text)\n",
    "\n",
    "# 定义格式化段落的函数\n",
    "def format_paragraph(text):\n",
    "    words = jieba.lcut(text)\n",
    "    formatted_text = \"\"\n",
    "    current_line = \"\"\n",
    "    for word in words:\n",
    "        current_line += word\n",
    "        if len(current_line.replace(\" \", \"\")) >= 20:\n",
    "            formatted_text += current_line.strip() + \"\\n\"\n",
    "            current_line = \"\"\n",
    "\n",
    "    if current_line:\n",
    "        formatted_text += current_line.strip()\n",
    "\n",
    "    return formatted_text\n",
    "\n",
    "# 生成完整文章的函数\n",
    "def generate_full_article(prompt, target_length=10000, paragraph_length=600):\n",
    "    article = \"\"\n",
    "    while len(article.replace(\" \", \"\")) < target_length:\n",
    "        paragraph = generate_paragraph(prompt, max_length=paragraph_length)\n",
    "        article += paragraph + \"\\n\\n\"\n",
    "        prompt = paragraph[-50:]  # 使用前一段落的最后部分作为下一段落的提示\n",
    "    return article\n",
    "\n",
    "# 提示文本\n",
    "prompt = \"寫一篇關於外星人的幻想文章：\"\n",
    "\n",
    "# 生成10,000字的文章\n",
    "article = generate_full_article(prompt, target_length=10000, paragraph_length=600)\n",
    "\n",
    "# 将文章保存到文件\n",
    "with open(\"generated_article_traditional.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(article)\n",
    "\n",
    "# 打印生成的文章\n",
    "print(\"生成的文章已保存到 generated_article_traditional.txt 文件中\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
